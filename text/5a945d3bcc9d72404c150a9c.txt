Title: Managing for Results - Performance Measures - Education - Maryland State Department of Education
Date: 10/02/2009
Type: Performance
URL: https://www.ola.state.md.us/umbraco/Api/ReportFile/GetReport?fileId=5a945d3bcc9d72404c150a9c
Extracted: 2025-06-18T11:00:12.220843
--------------------------------------------------------------------------------

--- Page 1 ---
Performance Audit Report
Managing for Results
Performance Measures
Education
Maryland State Department of Education
October 2009
OFFICE OF LEGISLATIVE AUDITS
DEPARTMENT OF LEGISLATIVE SERVICES
MARYLAND GENERAL ASSEMBLY

--- Page 2 ---
• This report and any related follow-up correspondence are available to the public through the
Office of Legislative Audits at 301 West Preston Street, Room 1202, Baltimore, Maryland
21201. The Office may be contacted by telephone at 410-946-5900, 301-970-5900, or 1-877-
486-9964.
• Electronic copies of our audit reports can be viewed or downloaded from our website at
http://www.ola.state.md.us.
• Alternate formats may be requested through the Maryland Relay Service at 1-800-735-2258.
• The Department of Legislative Services – Office of the Executive Director, 90 State Circle,
Annapolis, Maryland 21401 can also assist you in obtaining copies of our reports and related
correspondence. The Department may be contacted by telephone at 410- 946-5400 or 301-
970-5400.

--- Page 3 ---
DEPARTMENT OF LEGISLATIVE SERVICES
OFFICE OF LEGISLATIVE AUDITS
MARYLAND GENERAL ASSEMBLY
Karl S. Aro Bruce A. Myers, CPA
Executive Director Legislative Auditor xxx
October 2, 2009
Delegate Steven J. DeBoy, Sr., Co-Chair, Joint Audit Committee
Senator Verna L. Jones, Co-Chair, Joint Audit Committee
Members of Joint Audit Committee
Annapolis, Maryland
Ladies and Gentlemen:
We conducted a performance audit to determine the accuracy of selected
Managing for Results (MFR) performance measure data reported in the Maryland
fiscal year 2009 operating budget request. We also determined whether adequate
control systems were in place for collecting, summarizing, and reporting the
performance measure data.
As requested by the chairmen of the legislative budget committees, we are
systematically auditing the results of the 62 MFR measures contained in the
Managing for Results - State Comprehensive Plan, which was produced by the
Department of Budget and Management. This audit is the second to be conducted
on the 62 measures and focuses on the data reported for 6 of the 12 measures
contained within the Education portion of the State Comprehensive Plan. The
Maryland State Department of Education (MSDE) was responsible for reporting
these results. The other six Education measures are not the responsibility of
MSDE as these measures pertain to higher education. A list of the 62 MFR
measures is contained in Exhibit 3 of this report.
As a result of our audit, we have classified each of the six measures as either
Certified, Certified with Qualification, Inaccurate, or Factors Prevented
Certification. These designations are further described in Exhibit 2. Three of the
six measures included multiple sub-measure results that were separately evaluated
before a conclusion was drawn regarding the certification level for the measure as
a whole. If sub-measures within a given measure had differing certification

--- Page 4 ---
results, we concluded on the overall certification level for the measure by
considering the various sub-measure certification levels and the significance of
any variances. The audit results for the six measures are as follows:
Level of Certification
Factors Performance
Certified with
Certified Inaccurate Prevented Measures Audited
Qualification
Certification (See Exhibit 1)
2 2 - 2 6
The primary factor contributing to our inability to certify two measures was that
MSDE was not adequately ensuring that supporting data used to calculate the
measures were complete and accurate.
An Executive Summary of our findings can be found on page 3, immediately
following this cover letter, and our audit scope, objectives, and methodology are
explained on page 8. The response from MSDE to this audit is included as an
appendix to this report. We wish to acknowledge the cooperation extended to us
by MSDE during the audit.
Respectfully submitted,
Bruce A. Myers, CPA
Legislative Auditor
2

--- Page 5 ---
Executive Summary
Background Information
In July 1997, the Governor implemented the Managing for Results (MFR)
initiative, which is a strategic planning process used by department leaders and
others to establish direction and priorities for State programs to achieve
meaningful results. MFR requires State agencies to submit missions, goals,
objectives, and performance measures for each program as part of the annual
budget request. This information may then be considered in determining
Statewide spending priorities and the allocation of resources in agency budgets.
Effective July 1, 2004, the MFR process was established in State law, with the
Department of Budget and Management as the lead agency for developing a State
comprehensive plan for MFR. The resultant Managing for Results - State
Comprehensive Plan categorizes MFR goals into five functional areas, referred to
as pillars, which contain a total of 62 measures. As requested by the chairmen of
the legislative budget committees, we are systematically auditing these measures.
This audit is the second to be conducted pursuant to this request and focuses on
the data reported by the Maryland State Department of Education (MSDE) in the
Maryland fiscal year 2009 operating budget request for the 6 of the 12 measures
contained within the Education portion of the Plan (See Exhibit 1). A list of the
62 MFR measures is contained in Exhibit 3 of this report. Exhibit 4 references
the first MFR audit report issued by our Office which covered 13 measures in the
Public Safety and Safer Neighborhoods portion of the State Comprehensive Plan.
Conclusions
We concluded that for the six measures tested, two were Certified, two were
Certified with Qualification, and two were designated as Factors Prevented
Certification. Three of the six measures included multiple sub-measures.
Consequently, we evaluated each sub-measure and concluded on the overall
certification level for the applicable measure as a whole. For one of the measures
that was certified, we determined that one of the four sub-measures was
Inaccurate. However, the overall measure was Certified based on our
consideration of the certification levels for the other three sub-measures (which
were Certified) as well as the factors pertaining to the Inaccurate sub-measure. In
this regard, the Inaccurate designation resulted from a reporting issue (that is, the
wrong amount was reported) rather than a systemic problem. These results are
further described in the Findings section of this report.
3

--- Page 6 ---
Recommendations
The following detailed recommendations are among those we made to MSDE to
help strengthen the quality control processes and improve reporting for the
measures we audited.
• Establish procedures to ensure that all relevant data are included in the
measure calculation and that the data, including data obtained from third
parties, are reasonably accurate.
• Establish written definitions for all measures.
• Ensure that the reported performance measure represents the actual results
of the related measure calculation.
4

--- Page 7 ---
Findings
Certification Results
Agency,
Performance
Program Level of
Measure Results
Name and Certification Comments / Causes
(See Exhibit 1 for Reported
Budget (See Exhibit 2)
Definitions)
Reference1
MSDE Percent of students Academic Certified with MSDE could not substantiate that it verified certain data reported by Local
Office of the entering Year Qualification Education Agencies (LEAs) and used to calculate the measure. Specifically,
State kindergarten 2007 MSDE management advised us that it reconciled the reported information to
Superintendent demonstrating full audited enrollment data. However, this process was not adequately
Book 3, readiness on the 67.0% documented and controls were not in place to ensure that each mismatch
Pages 15, 16, 18 Work Sampling identified by the reconciliation was properly investigated. Consequently, data
System for certain students could be omitted without detection. Nevertheless, we
Kindergarten were able to determine that the calculated result was reasonably accurate
Assessment based on the data reported by the LEAs.
Percent of students Academic Certified with MSDE did not obtain sufficient documentation of the verification of
scoring “proficient” Year Qualification processes and related sub-measure results for the elementary and middle
or better by content 2007 school assessment tests and the high school assessment tests. Specifically,
area, grade and MSDE contracted with a third-party vendor to perform an evaluation of the
subgroup testing vendor’s processes and related results. However, MSDE could not
adequately document the scope of the third-party vendor’s verification or the
Reading – Grade 3 80.5% related findings to support the adequacy of the evaluation. For example,
Reading – Grade 8 68.2% MSDE had not received a report from the vendor or reviewed the vendor’s
Mathematics – 78.6% work to determine the adequacy of procedures performed by the vendor or
Grade 3 the propriety of conclusions drawn. Nevertheless, we were able to determine
Mathematics – 56.7% that the reported results for the various sub-measures were reasonably
Grade 8 accurate. MSDE also lacked formal definitions for the high school English 2
English 2 70.9% and Algebra proficiency measures.
Algebra 63.5%
1 Reference cited is the Maryland fiscal year 2009 operating budget request.
5

--- Page 8 ---
Certification Results
Agency, Performance
Level of
Program Name Measure Results
Certification Comments / Causes
and Budget (See Exhibit 1 Reported
(See Exhibit 2)
Reference1 for Definitions)
MSDE High school Academic Factors Prevented MSDE did not adequately ensure that data reported by LEAs and used in the
Office of the graduation rate Year Certification high school graduation rate were complete and accurate.2 Specifically, MSDE
State 2007 did not conduct comprehensive reviews of the data submitted by the LEAs.
Superintendent Rather, MSDE only compared the data to the prior year to identify significant
Book 3, 85.2% fluctuations and relied on LEA representations to justify fluctuations.
Page 19 Furthermore, this process relies on the prior year’s data, which were also not
verified. As a result, there was no assurance that the reported rate was
accurate.
Percent of high Academic Factors Prevented MSDE did not adequately ensure that data used in the drop-out rate
school drop-outs Year Certification calculation were complete and accurate. Specifically, as with the high school
2007 graduation rate, MSDE did not conduct comprehensive reviews of the data
submitted by the LEAs. Rather, MSDE only compared the data to the prior
3.5% year to identify significant fluctuations and relied on LEA representations to
justify fluctuations. The 3.5% drop-out rate represents 10,294 students who
dropped out.
For example, the calculation considers student transfers when determining the
total student population (denominator), but MSDE did not determine whether
all of those students designated as transferred to another school system
actually were re-enrolled in that school system (that is, whether the students
actually were dropouts that should be included in the numerator). Our review
of attendance data disclosed 1,979 students that were recorded as transfers to
another Maryland public school for which MSDE had no corresponding
record of a transfer to another Maryland public school. We contacted the
respective LEAs for 20 of these students to determine the disposition of the
transfers. The LEAs had no record of the reenrollment into a Maryland public
school for 17 of the students tested.
1 Reference cited is the Maryland fiscal year 2009 operating budget request.
2 The high school graduation rate calculation excludes certain data, such as students that did not graduate with the rest of their 9th grade starting class. Exclusion of this data results in the
reported graduation rate being higher than if the data were not excluded. The graduation formula is consistent with the MSDE published graduation rate definition and with the formula
used in several other states. During the 2006 legislative session, the Maryland General Assembly passed legislation redefining the graduation rate to include the number of students in
the four-year cohort (that is, the number of students who entered as a group in 9th grade plus/minus any transfers in grades nine through twelve). The legislation directed MSDE to use
the new definition after October 2011 and was to establish procedures to verify the accuracy of the data via statistical checks and on-site audits of the recordkeeping procedures at the
LEAs. Implementing these procedures would help MSDE address the deficiency we cited.
6

--- Page 9 ---
Certification Results
Agency, Performance
Level of
Program Name Measure Results
Certification Comments / Causes
and Budget (See Exhibit 1 Reported
(See Exhibit 2)
Reference1 for Definitions)
MSDE Percent of schools Academic Overall, the measure was deemed as Certified. The results for three sub-
Office of the that met Adequate Year Certified measures (Middle, High and Special Schools) were accurately calculated
State Yearly Progress 2007 and reported. However, an incorrect measurement result for elementary
Superintendent (AYP) in Reading schools demonstrating AYP in reading was reported by MSDE to the
Book 3, Department of Budget and Management for inclusion in the fiscal year 2009
Page 19 Elementary 77.4% budget book. Specifically, the reported result in the budget book was 77.4
Middle 50.9% percent instead of the 88.5 percent calculated by MSDE.
High 79.9%
Special Schools 39.1%
Percent of schools Academic Certified
that met Adequate Year
Yearly Progress 2007
(AYP) in
Mathematics
Elementary 89.4%
Middle 60.7%
High 83.9%
Special Schools 45.5%
1 Reference cited is the Maryland fiscal year 2009 operating budget request.
7

--- Page 10 ---
Scope, Objectives, and Methodology
Scope
Under the authority of the State Government Article, Section 2-1221 of the
Annotated Code of Maryland, we conducted an audit of selected performance
measure results reported in the Maryland fiscal year 2009 operating budget
request. The audit was performed in accordance with generally accepted
government auditing standards. Those standards require that we plan and perform
the audit to obtain sufficient, appropriate evidence to provide a reasonable basis
for our findings and conclusions based on our audit objectives. We believe that
the evidence obtained provides a reasonable basis for our findings and
conclusions based on our audit objectives.
As requested by the chairmen of the legislative budget committees, we are
systematically auditing the performance measures from the Managing for Results
- State Comprehensive Plan produced by the Department of Budget and
Management. This Plan includes 62 performance measures categorized into five
functional areas referred to as pillars. This audit is the second to be conducted
pursuant to this request and focuses on 6 of the 12 performance measures from the
Education functional area as reported by Maryland State Department of Education
(MSDE) in the Maryland fiscal year 2009 operating budget request. Three of the
six MSDE measures contained sub-measures resulting in our review of 17
separate MFR data elements.
Objectives
The objectives of our audit were (1) to determine whether the most recent actual
measurement results for the selected performance measures were accurately
reported in MSDE’s Maryland fiscal year 2009 operating budget requests and (2)
to determine whether adequate control systems existed over the collection and
reporting of the data related to the measurement results. Our performance audit
did not include an assessment of whether the performance measures reviewed
were consistent with the goals and objectives of the related programs, or were
meaningful indicators of program performance.
Methodology
To accomplish our objectives, we interviewed MSDE personnel responsible for
collecting and reporting the measure data, reviewed performance measure
calculations for accuracy, and determined whether these calculations were
consistent with the definitions of the performance measures as noted in Exhibit 1.
We used sampling techniques or other methods as deemed appropriate to test the
8

--- Page 11 ---
related source documents. We also analyzed MSDE’s performance measurement
data collection and reporting activities to evaluate whether proper controls existed
to ensure data integrity.
We developed a system to categorize the results of our audit of performance
measures. The four categories represent varying levels of certification of the
accuracy of the performance reported by the MSDE. The categories of
performance certification are defined in Exhibit 2. If during the course of our
audit of a measure we found circumstances that would require us to conclude that
the measure was either inaccurate or factors prevented certification, we did not
perform additional audit work that may have disclosed other factors that might
have adversely impacted the reported results. Certain of the six measures
evaluated included sub-measures that were separately evaluated before a
conclusion was drawn regarding the overall certification level for the measure. If
sub-measures within a given measure had differing certification levels, we
determined the overall certification level for the measure by considering the
prevalence of the various certification levels in the sub-measure and the
significance of any variances.
Our fieldwork was conducted on site at MSDE during the period from June 2008
to July 2009. The response from MSDE to our findings and recommendations
appears as an appendix in this report. As prescribed in State Government Article,
Section 2-1224 of the Annotated Code of Maryland, we will advise MSDE
regarding the results of our review of its response.
9

--- Page 12 ---
Exhibit 1
Definitions of the MSDE Education
Performance Measures Audited
Page 1 of 2
Performance
Definition1
Measure
Percent of students
entering
kindergarten The total number of kindergarten students evaluated and assessed by
demonstrating full their teachers as reaching the “full-readiness” level according to the
readiness on the Work Sampling System2 protocol and other assessment guidelines
Work Sampling divided by the total number of kindergarten students being evaluated
System during the first eight weeks of the current school year.
Kindergarten
Assessment
Percent of students Maryland School Assessment (MSA)3
scoring The number of students in grades 3 through 8 having a scale score of
“proficient” or proficient or greater on a particular MSA test (mathematics or
better by content reading) divided by the total number of all students taking that
area, grade, and particular MSA test.
subgroup
High School Assessment (HSA)4
No definition was available for the HSA measures.
Auditor’s Note – We were advised by MSDE personnel that the
definition for HSA is essentially the same as the definition for MSA,
just not specific to a particular grade since students take the HSA
tests at different grade levels after they complete the course in the
HSA subject area.
1 The definitions are substantially derived from those provided to DBM in annual State agencies’
Managing for Results budget submissions and DBM’s Managing for Results Annual Performance
Report. Additional information, such as data sources, was included in certain definitions in this exhibit
for informational purposes. Also, certain definitions were shortened to enhance readability.
2 The Work Sampling System is a set of indicators across various curricular areas that describe skills,
behavior, and knowledge of children entering kindergarten.
3 The MSA is a test of reading and math that meets the testing requirements of the federal No Child Left
Behind Act.
4 The HSA are tests that measure school and individual student progress toward Maryland high school
core learning goals.
10

--- Page 13 ---
Exhibit 1
Definitions of the MSDE Education
Performance Measures Audited
Page 2 of 2
Performance
Definition
Measure
High school The number of students who received a high school diploma during
graduation rate the current school year divided by the sum of the number of students
in grades 9, 10, or 11 who dropped out of school in the 3 prior years;
the number of current year grade 12 dropouts; and the number of
current year diploma recipients.
Percent of high The number of students in grades 9 through 12 who dropped out
school drop-outs during the school year divided by the number of grade 9 through 12
students who were in membership at any time during the school
year. The dropout rate definition includes any student who was in
membership during the school year in the total population including
students that transferred out of the State or died during the school
year and, thus, were not in attendance at the end of the school year.
Percent of schools The number of schools that met AYP in reading divided by the total
that met Adequate number of schools measured for AYP.
Yearly Progress
(AYP) in Reading Auditor’s note – AYP is the gain that schools, school systems,
and states must make each year in the proportion of students
achieving proficiency in reading and math based on MSA and
HSA testing results.
Percent of schools The number of schools that met AYP in mathematics divided by the
that met Adequate total number of schools measured for AYP.
Yearly Progress
(AYP) in
Mathematics
11

--- Page 14 ---
Exhibit 2
Categories of Performance Certification
Category Definition
Certified Reported performance was reasonably accurate.
Certified with Reported performance was reasonably accurate even though
Qualification either minor deficiencies were noted with the supporting
documentation, controls were not sufficient, or the
methodology used to calculate reported performance was not
consistent with the measure definition.
Inaccurate Reported performance differed significantly from actual
performance; the calculation process was wrong, such as
excluding data relevant to the calculation; or, as reported, the
measure was misleading, such as failing to disclose the
measure as a rate when applicable.
Factors Prevented Reported performance could not be verified, as documentation
Certification was unavailable, controls were not adequate to ensure the
accuracy of the results, or results were not presented in a
manner consistent with the performance measure description.
12

--- Page 15 ---
Exhibit 3
Managing for Results – State Comprehensive Plan
List of 62 Performance Measures in Plan
Page 1 of 4
Performance Area
Goal
MFR Measure
Public Safety and Safer Neighborhoods
Keeping Maryland communities safe – measured by
1 Firearm homicide rate per 100,000 (calendar year)
Recidivism: Percent of offenders returned to Department of Public Safety and
2 Correctional Services supervision for a new offense within one year of their release
from the Division of Correction - all releases
3 Traffic fatality rate per 100 million miles traveled (calendar year)
Maintaining necessary security standards in correctional institutions – measured by
Number of inmates who escape from all Division of Correction Facilities, Patuxent
4
Institution, and Division of Pretrial Detention and Services facilities (in aggregate)
Total number of inmates who walk off from Division of Correction minimum security
5
settings, prerelease or alternative confinement settings (in aggregate)
Providing effective rehabilitation and treatment services to offenders or substance abusers –
measured by
Percent of Proactive Community Supervision cases closed where the offender had
6
satisfactorily completed substance abuse treatment programs
Preventing youth violence, alcohol and substance abuse – measured by
Violent offense arrest rate for youths between 15 and 17 years of age (per 100,000
7
children per calendar year)
8 Recidivism: Percent of youth re-adjudicated or reconvicted within 1 year after release
Percent of 12th grade public school children who report using alcohol within the last 30
9
days
Percent of 10th grade public school children who report using heroin within the last 30
10
days
Protecting the well being of children – measured by
Rate of injury-related deaths due to accidents to children and youth between 0 and 19
11
years of age (per 100,000 children per calendar year)
Percent of children with recurrence of maltreatment within six months of first
12
occurrence
Statewide percent of current child support paid (Includes cases for persons who receive
13 public assistance, and for other persons who apply for child support services from the
Department of Human Resources)
13

--- Page 16 ---
Exhibit 3
Managing for Results – State Comprehensive Plan
List of 62 Performance Measures in Plan
Page 2 of 4
Performance Area
Goal
MFR Measure
Education
Children will enter school ready to learn – measured by
Percent of students entering Kindergarten demonstrating Full Readiness on the Work
1
Sampling System Kindergarten Assessment
Children will be successful in school – measured by
Percent of students scoring proficient or better by grade and content area
• Reading – Grade 3 – Total all groups
• Reading – Grade 8 – Total all groups
2 • Reading – Grade 10 – Total all groups
• Mathematics – Grade 3 – Total all groups
• Mathematics – Grade 8 – Total all groups
• Algebra – Total all groups
Children will complete school – measured by
3 High School Graduation Rate
4 Percent of children in grades 9 through 12 who drop out of school in an academic year
Schools will promote high levels of learning – measured by
5 Percent of schools demonstrating Adequate Yearly Progress in reading – State totals
Percent of schools demonstrating Adequate Yearly Progress in mathematics – State
6
totals
Higher Education
Promoting access and academic success in postsecondary education – measured by
Six year graduation rate of first-time, full-time students at Maryland public four-year
1
colleges and universities (all groups)
Percent of bachelor’s degrees awarded to racial/ethnic minorities at public and private
2
Maryland colleges and universities
Number of community college students who transfer to a Maryland public four-year
3
campus
Producing an educated and skilled workforce including addressing the State’s critical workforce
and healthcare needs – measured by
Number of graduates in teaching from Maryland’s public and private higher educational
4
institutions
Percent of teacher candidates from Maryland public and private higher educational
5
institutions who pass Praxis II
Number of graduates in nursing from Maryland public and private higher educational
6
institutions
14

--- Page 17 ---
Exhibit 3
Managing for Results – State Comprehensive Plan
List of 62 Performance Measures in Plan
Page 3 of 4
Performance Area
Goal
MFR Measure
Health
Promoting health and well being: Babies Born healthy – measured by
1 Infant mortality rate for all races (per 1,000 live births)
2 Rate of live births to adolescents between 15 and 19 years of age (per 1,000 women)
Promoting health and well being: Healthy children, adolescents, and adults – measured by
3 Percent of Maryland children fully immunized (by 24 months)
4 Number of children under 6 years of age with elevated blood lead levels (>10ug/dl)
Cumulative percent change from the calendar year 2000 baseline for underage high
5
school students smoking cigarettes
Overall cancer mortality rate per 100,000 persons (age adjusted to 2000 U.S. Standard
6
Population)
7 Percent change in number of new HIV cases from calendar year 2000 baseline
8 Rate of primary/secondary syphilis incidence (cases per 100,000)
Number of reported cases of vaccine preventable communicable diseases including
9
hepatitis A, measles, mumps, pertussis
Promoting health and well being: Services to the disability community – measured by
Number of people with disabilities who achieved successful employment through
10 assistance by the Department of Education’s Disability Rehabilitation Services
rehabilitation programs
Percent of Developmental Disabilities Administration Community Service respondents
11 of the “Ask ME Survey” who expressed satisfaction with physical well-being, personal
development, and self-determination (reported separately)
Promoting health and well being: Substance abuse treatment – measured by
12 Percent of substance use decrease during substance abuse treatment
Promoting health and well being: Mental health services – measured by
Percent of adults who report mental health services have allowed them to deal more
13
effectively with daily problems
Environment
Restoring the health of the Chesapeake Bay and its living resources – measured by
1 Acres of submerged aquatic vegetation
2 Blue crab landings (3 year average)
3 Oyster landings (3 year average)
4 Estimated nitrogen load to the Chesapeake Bay from Maryland (in million pounds)
Improving and protecting water quality and ensuring safe drinking water – measured by
5 Watersheds impaired by nutrients
Percent of Marylanders served by public water systems in significant compliance with
6
all rules adopted as of 2002
15

--- Page 18 ---
Exhibit 3
Managing for Results – State Comprehensive Plan
List of 62 Performance Measures in Plan
Page 4 of 4
Performance Area
Goal
MFR Measure
Ensuring clean air – measured by
7 Three year average of days the one-hour ozone standard was exceeded
Restoring contaminated industrial sites to productive use – measured by
Number of acres of property in the Voluntary Clean-up Program completed and a No
8
Further Requirements Determination or a Certificate of Completion issued
Reducing hazardous waste and hazardous materials in the environment – measured by
9 Number of remedial actions at all State Superfund sites that are completed
Commerce
Helping businesses to grow and create jobs – measured by
1 Percent change in Maryland employment from the 2001 baseline (12 month average)
2 Rate that adult employment trainees enter employment
3 Maryland Port Administration total general cargo tonnage, (thousands)
Estimated direct expenditures from film, television, and other production activities in
4
Maryland
5 Annual Baltimore Washington International Airport passenger growth rate
Improving the State’s transportation infrastructure – measured by
6 Percent of State system roadway mileage with acceptable ride quality
Percent of bridges on the State portion of the National Highway System that will allow
7
all legally loaded vehicles to safely traverse
8 Total ridership for bus and rail transit (in millions)
System Preservation Funding Levels in the Consolidated Transportation Program (in
9
millions)
Invigorating communities – measured by
10 Home ownership
11 Annual percent change in Maryland per capita personal income
12 Total acres enrolled in agricultural preservation districts
Making the most of Maryland’s history and culture – measured by
Value of rehabilitation expenditures approved for the State Rehabilitation Tax Credit for
13
restoration and preservation of historic properties
Fiscal Responsibility
Effective resource management – measured by
1 Number of fiscal years closed with a positive General Fund balance
Maintaining a triple A bond rating from all three nationally recognized bond rating
2
agencies for each issuance of State General Obligation Bonds
16

--- Page 19 ---
Exhibit 4
Managing for Results Audit Reports Previously Issued by
the Office of Legislative Audits Pertaining to the 62 Measures
Number of
Report Report Date Measures
Audited
Public Safety and Safer Neighborhoods March 19, 2009 13
17

--- Page 21 ---
Managing for Results - Fiscal Year 2009
Responses to Performance Measures Audit
State Department of Education
Performance Measure:
Percent of students entering kindergarten demonstrating a full readiness on the Maryland
Model for School Readiness Kindergarten Assessment.
Comment:
We agree with the finding and recommendation. MSDE performed several tests, some of which
were performed in concert with a third party vendor, that were designed to test the integrity of
data reported by the LEAs. One of these tests, as noted in the finding, was reconciliation between
enrollment data and assessment data. MSDE agrees that while many of the mismatches
identified as a result of the reconciliation process were properly resolved, controls were not
complete to assure that each mismatch was properly investigated and documented. In the future,
MSDE will strengthen existing controls, utilizing the newly established unique student
identification numbers, which will ensure that each mismatch is properly investigated, resolved
and documented. These additional procedures will help to ensure the accuracy of the calculation
of this Performance Measure in the future.
Performance Measure:
Percent of students scoring “proficient” or better by content area, grade and subgroup:
• Reading – Grade 3
• Reading – Grade 8
• Mathematics – Grade 3
• Mathematics – Grade 8
• English 2
• Algebra
Comment:
We agree with the finding and recommendation. The third-party vendor’s reviews of Maryland’s
assessments are ongoing, conducted mainly through conference calls and e-mails, and include
approvals along the way for process implementation and accuracy of statistical results. It is not
a one-time process that is completed within a short time span. In this regard, the third-party
vendor, the testing vendor, and MSDE staff participate in meetings and conference calls (along
with the other vendors) and decisions are implemented according to the third-party vendor’s
direction. The evaluation is formative; as such, it takes place as each test is being developed
and analyzed. The process of sequential evaluation ensures that the development of scoring

--- Page 22 ---
Managing for Results – Fiscal Year 2009
Responses to Performance Measurement Audit
State Department of Education
(Page 2 of 4)
results does not move to the next step without the third-party vendor’s verification. The entire
process is documented by the testing vendor in a Technical Report for each assessment each
year. The third-party vendor reviews this report for accuracy and completeness as thorough
documentation of all processes and the accuracy of results.
MSDE has extensive documentation regarding review and verification processes employed by
the third-party vendor up to the issuance of the Technical Report by the testing vendor. The
third-party vendor did perform the verification of the FY07 Technical Report, but during the
audit MSDE was not able to produce documentation to support the review. This lack of
documentation is due solely to administrative error, and documentation for a similar review for
FY08 is on file. As recommended, MSDE is strengthening its procedures and controls to ensure
that, in the future, planned verification procedures are performed and that the results of the
planned verifications are properly documented and maintained.
The finding also indicated that MSDE lacked a formal definition for the high school English 2
and Algebra proficiency measure. The High School Assessment (HSA) serves as the high school
version of the Maryland School Assessment (MSA) and therefore has the same definition. In the
future, MSDE will provide a definition for the high school MSA to clarify this point.
Performance Measure:
High school graduation rate
Comment:
We agree with the finding and recommendation. MSDE has developed several procedures which
will provide assurance that the data provided by the LEAs used in the calculation of the high
school graduation rate are complete and accurate. Specifically:
• In the 2008-2009 school year, MSDE defined a new report for grade 12 students that
identified students coded as receiving a Maryland Diploma on the End-of-Year
attendance file. This file was matched to the High School Status Model data collection to
determine if students met the graduation requirements to receive a Maryland High School
Diploma. Procedures were established for the creation of the report and the follow-up
required with local school systems. This process will be performed for future years.
• Drop-outs are an integral component of the Leaver graduation rate formula currently
being used through the 2009-2010 school year. Improvements that will ensure the
accuracy of the drop-out data reported by LEAs to MSDE are described in the Corrective
Action Plan for high school drop-outs.

--- Page 23 ---
Managing for Results – Fiscal Year 2009
Responses to Performance Measurement Audit
State Department of Education
(Page 3 of 4)
• Commencing with FY11, the State Aid Audit Plan will be modified to test a sample of
Maryland Diplomas awarded to students to verify compliance with graduation
requirements specified by COMAR 13A.03.02.08.
• Commencing with the 2010-2011 school year, MSDE will implement the newly defined
graduation cohort rate as required by the United States Department of Education for use
in 2012 and comply with the documentation requirements. The final regulations address
the following critical issues:
o Ensures that students who drop out are not counted as “transfers.”
o Gives credit for students who take longer than four years to graduate.
o Holds schools accountable for improving graduation rates for all students and
subgroups.
• To remove a student from the cohort, a school or Local Education Agency (LEA) must
confirm to MSDE in writing that the student:
o Transferred out (with verifiable official written documentation retained by the LEA
that the student enrolled in another school or educational program that culminates
in the award of a regular high school diploma); or
o Emigrated to another country; or
o Is deceased.
The above actions will strengthen MSDE’s controls and provide assurance that the data
reported by the LEAs used in future calculation of the high school graduation rate are complete
and accurate.
Performance Measure:
Percent of high school drop-outs
Comment:
We agree with the finding and recommendation. During the 2008-2009 school year, MSDE
defined a new report for grade 12 students to identify students designated as transfers to another
school system who were not re-enrolled in another local school system across the state.
Procedures were established for the creation of the report and the follow-up required with local
school systems. The new report is known as the “Cross LEA (Local Education Agency)
Validation Report.” During the 2009-2010 school year, MSDE will expand this report to also
include grades 9 through 11. Local school systems are required to review this report and make

--- Page 24 ---
Managing for Results – Fiscal Year 2009
Responses to Performance Measurement Audit
State Department of Education
(Page 4 of 4 )
changes to their data file submission by changing the transfer student to a withdrawal if they are
unable to substantiate the transfer code within their student records. In addition, commencing
with FY11, the State Aid Audit Plan will be modified to test, on a sample basis, the accuracy of
student transfer data reported to MSDE by the LEAs. The above actions, when taken in concert
with the existing Z-Test verification procedure, will provide assurance that data reported by the
LEAs used in the calculation of the high school drop-out rate are complete and accurate.

--- Page 25 ---
A T
UDIT EAM
Brian S. Tanen, CPA, CFE
Audit Manager
Nelson W. Hopkins, CPA
Senior Auditor
David S. Propper
Robert A. Wells
Staff Auditors