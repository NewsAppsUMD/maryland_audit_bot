Title: State Employee Performance Evaluation Program
Date: 06/27/2018
Type: Performance
URL: https://www.ola.state.md.us/umbraco/Api/ReportFile/GetReport?fileId=5b3e23f94212030cc85070b2
Extracted: 2025-06-18T22:16:23.151989
--------------------------------------------------------------------------------

--- Page 1 ---
Performance Audit Report
State Employee Performance Evaluation Program
Assessment of the Department of Budget and Management’s Oversight and
Select Agencies’ Administration of the Program
June 2018
OFFICE OF LEGISLATIVE AUDITS
DEPARTMENT OF LEGISLATIVE SERVICES
MARYLAND GENERAL ASSEMBLY

--- Page 2 ---
For further information concerning this report contact:
Department of Legislative Services
Office of Legislative Audits
301 West Preston Street, Room 1202
Baltimore, Maryland 21201
Phone: 410-946-5900 · 301-970-5900
Toll Free in Maryland: 1-877-486-9964
Maryland Relay: 711
TTY: 410-946-5401 · 301-970-5401
E-mail: OLAWebmaster@ola.state.md.us
Website: www.ola.state.md.us
The Office of Legislative Audits operates a Fraud Hotline to report fraud, waste, or abuse
involving State of Maryland government resources. Reports of fraud, waste, or abuse may
be communicated anonymously by a toll-free call to 1-877-FRAUD-11, by mail to the Fraud
Hotline, c/o Office of Legislative Audits, or through the Office’s website.
The Department of Legislative Services does not discriminate on the basis of age, ancestry,
color, creed, marital status, national origin, race, religion, gender, gender identity, sexual
orientation, or disability in the admission or access to its programs, services, or activities. The
Department’s Information Officer has been designated to coordinate compliance with the
nondiscrimination requirements contained in Section 35.107 of the Department of Justice
Regulations. Requests for assistance should be directed to the Information Officer at 410-946-
5400 or 410-970-5400.

--- Page 6 ---
4

--- Page 7 ---
Table of Contents
Background Information 8
Overview 8
Department of Budget and Management (DBM) Responsibilities 8
Performance Evaluation Program (PEP) 9
Evaluation Results Reporting Process 11
Maryland Department of Transportation Performance Appraisals 11
Audit Scope, Objectives, and Methodology 13
Audit Scope 13
Objectives 13
Methodology 13
Fieldwork and Agency Responses 16
Conclusions 17
Findings and Recommendations 21
Objective 1 – Assess DBM – Office of Personnel Services and Benefits’ 21
(OPSB’s) Efforts to Ensure Employee Performance Evaluations Are
Given and the Results Are Accurately Reported
Finding 1– Many employees had not received required 21
evaluations during a five-year period and OPSB had not
established a comprehensive strategy to improve agency
compliance or ensure agencies monitored their efforts.
Finding 2 – OPSB did not disclose certain information in the 23
Annual Personnel Report needed to better interpret and clarify
the performance evaluation results. In addition, complete
records supporting the Report were not maintained and controls
were not established to ensure the accuracy of the underlying
data.
Objective 2 – Assess OPSB’s Efforts to Ensure Completed Performance 28
Evaluations Contain Required Content, Supervisors Receive Mandatory
PEP Training, and the Overall Purpose of the PEP Was Being Achieved
5

--- Page 8 ---
Finding 3 – OPSB had not established a process to ensure 28
performance evaluations were based on measurable standards
and their content met legal requirements.
Finding 4 – OPSB did not clearly set the expectations for required 31
mandatory PEP-related training for supervisory and managerial
employees, require the maintenance of agency-based training
records, or monitor agency training efforts.
Finding 5 – OPSB had not developed approaches to formally 33
evaluate the effectiveness of the PEP and the training courses
for managers and supervisors.
Objective 3 – Assess Selected Agencies’ Procedures for Monitoring the 35
Proper Completion of Performance Evaluations for Their Employees and
Providing Related Training to Supervisors
Finding 6 – Certain agencies that were not using available personnel 35
system records to monitor completion of performance evaluations
had many employees who were not evaluated. None of the five
agencies we reviewed had established controls over the recording
of evaluation data in the personnel systems.
Finding 7 – None of the five agencies we reviewed had effectively 38
monitored the content of performance evaluations given to
employees for compliance with legal requirements or policy.
Finding 8 – None of the five agencies we reviewed had established 42
a documented process to sufficiently track and monitor each of
their supervisors to ensure they had received performance
appraisal training.
Exhibit 1 – DBM Annual Personnel Report of Employee Performance 44
for Fiscal Year 2016
Exhibit 2 – Breakdown of All Other Agencies Category from 46
Fiscal Year 2016 Annual Personnel Report
Exhibit 3 – State of Maryland Performance Evaluation for 49
Non-Supervisory Employees
Exhibit 4 – Results from OLA Employee Performance Evaluation Survey 53
6

--- Page 9 ---
Exhibit 5 – Results from OLA Supervisor Performance Evaluation Survey 57
Agency Responses Appendix
7

--- Page 10 ---
Background Information
Overview
State law requires appointing authorities of agencies under the Department of
Budget and Management’s (DBM) authority to ensure that supervisors meet
with each employee to prepare performance evaluations at six-month
intervals. This law requires supervisors to review and discuss the evaluation
with each employee to promote agreement and understanding about the
performance evaluation, to establish measurable tasks to achieve, and to
identify any areas where training may be needed. In addition, the law requires
that the end-of-year performance appraisal must include written specific tasks
to be achieved during the next rating period and an overall performance rating
of outstanding, satisfactory, or unsatisfactory. After each six-month
evaluation, agency human resources staff record the overall performance
rating for each employee in DBM’s State Personnel System (SPS).
Certain State agencies, with independent personnel management systems,
are exempt from DBM oversight, but must establish their own employee
performance evaluation programs. Such programs could differ from DBM’s.
For example, State regulations established by the Maryland Department of
Transportation (MDOT) require annual, versus biannual, employee
performance appraisals in accordance with policies established by MDOT,
which also differ from DBM’s.
State law requires DBM to compile and report Executive Branch agencies’
(also, generally including those with independent personnel systems)
employee performance information and other personnel information in an
annual personnel report (APR) to the Governor and General Assembly due by
January 1st. Department of Budget and Management – Office of Personnel
Services and Benefits (OPSB) employees prepare the APR by manually
compiling performance evaluation ratings recorded in SPS for each agency for
the six-month period ending June 30th as well as the number of employee
performance appraisals reported by MDOT.
Department of Budget and Management Responsibilities
State Personnel and Pensions Article, Title 6, Subtitle 1 of the Annotated Code
of Maryland, establishes the State Personnel Management System (SPMS) to
provide a system of employment for employees under the authority of the
Secretary of DBM. SPMS establishes employment categories, including
executive, management, professional, and skilled service. SPMS also
8

--- Page 11 ---
establishes procedures for appointment, promotion, discipline, termination,
and other aspects of human resources management. SPMS includes all
Executive Branch employees with the exception of certain agencies with
authority to establish independent personnel systems, such as MDOT and the
University System of Maryland (USM).
DBM utilizes an automated personnel system, SPS, to maintain human
resource records for SPMS employees. SPS includes various modules for
maintaining records pertaining to employee time and attendance, personnel
information, job applications, and online learning. SPS agency payroll data is
electronically transmitted to the Comptroller of Maryland – Central Payroll
Bureau (CPB) to process State employee payroll. According to CPB records,
there were approximately 44,800 employees covered by the SPMS with
payroll costs in calendar year 2015 totaling approximately $2.9 billion.
According to SPS, there were 3,200 employees in management and 4,200
supervisors for SPMS agencies as of July 17, 2017.
State Personnel and Pensions Article, Section 4-108 of the Annotated Code of
Maryland, provides that the DBM Secretary shall periodically conduct
investigations and make visits to various units to determine the enforcement
and effect of State personnel laws and regulations and the methods of
administration of SPMS. State Personnel and Pensions Article, Title 4,
Subtitle 3 of the Annotated Code of Maryland requires DBM to compile and
report Executive Branch agencies’ employee performance information and
other personnel information in an APR to the Governor and General Assembly.
The APR is to include employees from all Executive Branch agencies, including
agencies with independent personnel systems excluding USM. The APR
preparation function is performed by OPSB.
Performance Evaluation Program (PEP)
State Personnel and Pensions Article, Title 7, Subtitle 5 of the Annotated Code
of Maryland, requires each agency appointing authority to ensure two
evaluations of the performance of each State employee in SPMS under the
authority of DBM are completed at six-month intervals in accordance with
procedures established by the DBM Secretary. Agency appointing authorities
are generally management employees with the power to make appointments
and recommend terminations. Further, this law requires DBM to provide
mandatory training to each agency’s supervisors on the methods and
procedures required in the performance evaluation process.
This law requires supervisors to prepare an informal mid-year performance
appraisal for each employee under their supervision and to review and
9

--- Page 12 ---
discuss the appraisal with each employee. The purposes of the discussion
include promoting agreement and understanding about the performance
appraisal, establishing measurable tasks to achieve, and identifying any areas
where training may be needed. The end-of-year performance appraisal must
be approved by the appointing authority. The appraisal shall include the
employee’s performance rating, the specific tasks the employee is to achieve
during the next rating period, any necessary modifications to the employee’s
position description, and training recommendations. Performance appraisals
are documented on the PEP form developed by OPSB.
State law requires that employees receive an informal mid-year performance
appraisal as well as an end-of-year performance appraisal with an overall
performance rating of outstanding, satisfactory, or unsatisfactory. According
to OPSB guidelines, an individual employee’s PEP cycle (that is, rating period)
begins either January 1st or July 1st depending on the employee’s entry-on-
duty (EOD) date (the date the employee began employment with the State,
which may be different than his/her current agency hiring date). For
employees with EOD dates prior to July 1st, the PEP cycle begins on January 1st
while the cycle begins on July 1st for employees hired after July 1st.
Consequently, the end-of-year appraisal will be due annually by December
31st or June 30th.
According to guidelines established by DBM, PEP is intended to facilitate
communication between employees and supervisors regarding expectations
and job performance. The process offers employees and supervisors an
opportunity to acknowledge the successes achieved over the year, and to
openly discuss areas for enhancement and improvement. In cases of poor
performance, it is meant to complement the disciplinary process by providing
a means to assist employees to improve.
As shown in Graph 1 on the following page, according to the APR for fiscal
years 2012 through 2016, the agencies reported that from 83.9 to 90.8
percent of their State employees received performance evaluations. For
example, the APR as of June 30, 2015, indicated that 38,814 (86.1 percent)
employees received ratings out of 45,090 employees to be rated. The APR as
of June 30, 2016, indicated that 37,999 (83.9 percent) employees received
ratings out of 45,271 employees to be rated. This 2016 report included both
mid-year and end-of-year evaluation results, which included ratings categories
of Outstanding (34.6 percent), Satisfactory (64.9 percent), and Unsatisfactory
(0.5 percent). These APRs reflect only regular (not contractual) full-time
employees.
10

--- Page 13 ---
Graph 1
Employee Evaluation Completion Rates
92.0%
90.6% 90.8%
90.0%
88.0%
86.0% 87.3%
86.1%
84.0%
83.9%
82.0%
80.0%
2012 2013 2014 2015 2016
Percent of Employees Rated
Source: OLA calculations based on DBM Annual Personnel Reports
Evaluation Results Reporting Process
OPSB guidelines require agency supervisors to forward completed evaluations
to their agency’s human resources unit, which is required to report the
evaluation results to DBM. To accomplish this reporting requirement, State
agency human resource staff record statistics summarizing their agency
performance evaluation results for all employees in SPS, except for Executive
Branch agencies with independent personnel systems, such as MDOT. The
evaluation data recorded in SPS for each employee is limited to the type of
evaluation (mid-cycle or end-of-cycle), the evaluation period, and the overall
rating of Outstanding, Satisfactory, or Unsatisfactory. OPSB uses the SPS
evaluation records to track the progress of agencies in completing
performance evaluations for preparation of the APR due January 1st each
year. Each December, OPSB contacts agencies with a low evaluation
completion rate to remind agency personnel staff that evaluations are past
due for the period ending June 30th. As necessary, OPSB employees manually
compile and adjust the SPS evaluation data to prepare the APR.
MDOT Performance Appraisals
Transportation Article, Section 2-103.4 of the Annotated Code of Maryland,
authorized MDOT to establish a human resources management system for
employees of the Department and its units. MDOT is comprised of the
Secretary’s Office and five business units and one authority: State Highway
Administration, Maryland Transit Administration, Motor Vehicle Administration,
11

--- Page 14 ---
Maryland Port Administration, Maryland Aviation Administration, and the
Maryland Transportation Authority (MDTA).
MDOT established an alternative evaluation system that is governed by State
regulations and its own human resources policy on employee performance
appraisals, which applies to all units except MDTA because MDTA established
an independent personnel system. This MDOT policy requires all employees
be evaluated at least annually in the form of an appraisal interview and
requires all employee appraisals include a development plan or an
improvement plan along with an overall rating based on ratings for pre-
established general, job specific, and leadership factors.
The Secretary’s Office delegates the responsibility for ensuring performance
appraisals are completed properly to each unit. The overall appraisal ratings
are recorded in MDOT’s Human Resources Information System (HRIS) by each
unit’s human resources staff and are reported in summary to OPSB by the
Secretary’s Office. MDOT performance appraisals are completed on a
calendar year basis, and the annual appraisal results are reported to OPSB for
inclusion in OPSB’s APR for the subsequent fiscal year (for example, calendar
year 2015 appraisals were reported in the fiscal year 2016 report). According
to a February 17, 2017 report from the HRIS system, MDOT had 5,860
employees, excluding MDTA.
12

--- Page 15 ---
Audit Scope, Objectives, and Methodology
Audit Scope
We conducted a performance audit of certain aspects of the State employee
Performance Evaluation Program (PEP), which requires all State employees of
agencies under Department of Budget and Management (DBM) authority to
receive periodic performance evaluations. We also reviewed certain aspects
of the Maryland Department of Transportation’s (MDOT) employee
performance evaluation program, with the exclusion of the Maryland
Transportation Authority (MDTA). Our audit included a review of the program
oversight provided by DBM’s Office of Personnel Services and Benefits (OPSB)
and MDOT and a review of OPSB’s and applicable State agencies’ policies and
procedures to ensure evaluations were properly completed.
Objectives
Our audit had three objectives:
1. Assess OPSB’s efforts to ensure employee performance evaluations are
given and the results are accurately reported.
2. Assess OPSB’s efforts to ensure completed performance evaluations
contain required content, supervisors receive mandatory PEP training, and
the overall purpose of the PEP was being achieved.
3. Assess selected agencies’ procedures for monitoring the proper
completion of performance evaluations for their employees and providing
related training to supervisors.
Methodology
To accomplish our first objective, we reviewed applicable State laws and the
policies and procedures established by OPSB governing the PEP and
established by MDOT to govern its performance evaluation program. We
interviewed personnel at OPSB and MDOT to determine program objectives
and to identify processes and related controls to ensure evaluations were
completed and evaluations were recorded in the State Personnel System
(SPS) and MDOT’s Human Resources Information System (HRIS).
We also reviewed OPSB records used to prepare the annual personnel report
(APR) submitted to the Governor and General Assembly. These records
13

--- Page 16 ---
included reports extracted by OPSB from SPS, manual spreadsheets
maintained by OPSB employees, and email correspondence between OPSB
and State agency human resources employees. We judgmentally selected
agencies from the APR to test the accuracy of evaluation ratings recorded in
SPS as compared to completed performance evaluation documentation. We
also obtained data files of all current State employees from SPS and HRIS,
which we deemed reliable for our purposes. We used these files for various
purposes during the audit, including a determination of the number of
employees that had not received performance evaluations.
We also obtained a data file from the Comptroller of Maryland – Central
Payroll Bureau (CPB) that listed all regular, full-time State employees issued
payroll payments during calendar years 2014 through 2016, which we
deemed reliable for our purposes. We reviewed and sorted this file and
extracted all employees for Executive Branch agencies (excluding State
universities and colleges)1, and then conducted random statistical samples of
all employees Statewide in this extracted file for proper completion of
performance evaluations in fiscal year 2016. Our test objective was to use
this data to verify the reasonableness of the overall number of evaluations
completed as reported in the Annual Personnel Report as of June 30, 2016.
Specifically, our random statistical sample size of 131 employees was
determined based on a 90 percent confidence level, with 5 percent precision,
and a projected error rate of 14 percent based on our preliminary testing.
For our second objective, we interviewed OPSB employees to identify
processes to ensure completed performance evaluations contain required
content. We also used the aforementioned selection of 131 evaluations to
assess the content and completion for only those employees under DBM
oversight (that is, we excluded the MDOT employees). Therefore, the results
could not be used to conclude on the overall Statewide population. We also
used the results of our review of certain evaluations as part of our work under
Objective 3, which is described below, to further comment on evaluation
content and completion.
We also reviewed OPSB’s PEP training course materials and training records
to determine if OPSB ensured all agency supervisors received mandatory PEP
training. To assess whether the overall purpose of the PEP was being
achieved, we invited 95 employees and 106 supervisors selected from our
statewide statistical test to complete an anonymous online survey, so as to
obtain their opinions on whether evaluations were properly completed and
1 We excluded State universities and colleges to be consistent with OPSB’s PEP Guidelines,
which also excluded them (inappropriately, as we subsequently determined based on State
law) from OPSB’s oversight.
14

--- Page 17 ---
whether the evaluation program was effective.2 We have included the survey
questions and results as Exhibits 3 and 4.
For our third objective, we interviewed employees and reviewed evaluation
documentation and training records from the five large State agencies shown
in Table 1 to identify how they implemented performance evaluation program
policies and procedures. We also determined whether they ensured
evaluations were properly completed for all employees, and evaluation
training was provided to all supervisors:
Table 1
State Agencies Selected for Review
Number of Employees to be Rated
June 30, 2016
Agency Number of
Employees
1 Department of Public Safety and Correctional Services 9,566
2 Maryland Department of Health 7,967
3 Maryland Department of Transportation 5,868
4 Department of Human Services 5,788
5 Department of Natural Resources 1,214
Total 30,403
Source: DBM Annual Personnel Reports
To determine the extent to which evaluations were completed for employees
of each of the aforementioned 5 agencies for fiscal years 2015 and 2016, we
employed a statistical sampling methodology for each agency. Collectively, we
selected from the CPB records 591 employees (521 employees from the four
agencies under DBM oversight and 70 MDOT employees). Our sampling
methodology assumed a 90 percent confidence level, 5 percent precision,
and projected error rates ranging from 3 percent to 30 percent based on our
preliminary testing at each of the 5 agencies.
2 Our statewide statistical test of evaluations consisted of 131 employees selected from CPB
records. For the on-line survey, we excluded 19 MDOT employees because they utilized an
alternative evaluation form. An additional 17 employees could not be contacted because
they had left state service or did not have a valid e-mail address, resulting in the 95
employees invited to participate in the online survey. We also invited 106 of the 131
employee’s supervisors, excluding MDOT, to complete the survey who were still employed
and had a valid e-mail address, which was used to invite survey participation.
15

--- Page 18 ---
We also used a portion of the sample population to conduct tests to assess
whether the content of those evaluations met applicable State requirements
or policy. That is, for the four agencies under DBM oversight, we only used the
189 year-end evaluations prepared for the six-month period ended June 30,
2016 to perform the tests. (The remaining 332 employees either did not have
an evaluation on file for that period or received an interim evaluation.)
Consequently, test results could not be projected to the entire population of
employees for each agency. The calendar year 2015 evaluations for all 70
MDOT employees were used to conduct the test of content. We chose not to
use the results to conclude on the overall MDOT population.
Our audit was performed in accordance with generally accepted government
auditing standards. Those standards require that we plan and perform the
audit to obtain sufficient, appropriate evidence to provide a reasonable basis
for our findings and conclusions based on our audit objectives. We believe
that the evidence obtained provides a reasonable basis for our findings and
conclusions based on our audit objectives.
Fieldwork and Agency Responses
Our fieldwork was completed during the period from October 2016 through
December 2017. A copy of the draft report was provided to DBM – OPSB and
to the Department of Public Safety and Correctional Services (DPSCS),
Maryland Department of Health (MDH), Department of Human Services (DHS),
Department of Natural Resources (DNR), and Maryland Department of
Transportation (MDOT). The responses to our findings and recommendations
from DBM – OPSB to Findings 1, 2, 3, 4, and 5, and the responses from
DPSCS, MDH, DHS, DNR, and MDOT to Findings 6, 7, and 8, appear as an
appendix to this report. As prescribed in State Government Article, Section 2-
1224 of the Annotated Code of Maryland, we will advise the agencies
regarding the results of our review of their responses.
16

--- Page 19 ---
Conclusions
We concluded that improvements were needed over the Department of
Budget and Management (DBM) – Office of Personnel Services and Benefits’
(OPSB) efforts to ensure that evaluations were given to employees as required
and reported accurately on an annual basis. We also found that OPSB did not
have processes in place to ensure that all evaluations were properly
completed, supervisors received required Performance Evaluation Program
(PEP) training, and the overall purpose of PEP was achieved. Finally,
opportunities were identified, which we believe will improve State agency
procedures to ensure that all required evaluations were properly prepared and
delivered to employees and that supervisors received required comprehensive
training on the evaluation process.
Our audit found that many employees of the agencies under DBM’s authority
did not receive required evaluations. According to the Annual Personnel
Reports (APR) for fiscal years 2012 through 2016, State agencies reported
that from 83.9 to 90.8 percent of their State employees received performance
evaluations. For example, the APR as of June 30, 2016, indicated that
37,999 (83.9 percent) employees received ratings out of 45,271 full-time,
regular employees to be rated (see Exhibit 1). In addition, OPSB lacked a
comprehensive strategy to improve agency compliance with the evaluation
requirements in State law. OPSB had not established a process to routinely
follow-up with agencies that reported high numbers of evaluations that were
not completed by notifying management and seeking corrective actions when
warranted.
OPSB had not established requirements that agencies monitor the
recordation and completion of evaluations using the State Personnel System
(SPS) or other internal tracking mechanisms. For example, our review of the
evaluation procedures for four agencies with large employee populations as of
June 30, 2016 disclosed that each had a process to record certain evaluation
information in SPS. However, the two agencies with the highest annual
percentage (96.5 and 99.5 percent) of evaluated employees had established
internal evaluation tracking procedures using available reports in SPS.
We also identified certain conditions that if addressed could lead to enhanced
reliability and usefulness of the APR. Specifically, OPSB did not disclose
certain information regarding the methodology used to prepare the APR,
inappropriately excluded data from certain agencies, and combined the
results of 41 agencies into one “All Other Agencies” category, resulting in a
loss of individual agency accountability (see Exhibits 1 and 2). For example,
the APR did not state that the performance data reported only reflected
17

--- Page 20 ---
evaluations, both informal mid-cycle and comprehensive end-of-cycle, that
were due for the six-month period ended June 30th rather than provide data
for the entire fiscal year, although this data was available in SPS.
Furthermore, OPSB had not developed automated processes to support the
APR results. Instead, OPSB manually compiled the evaluation data, but had
not established the necessary recordkeeping controls. Specifically, OPSB did
not verify that agencies properly recorded in SPS the applicable information
from paper copies of evaluations, or more importantly, that an evaluation was
actually prepared when so indicated in SPS.
We also found that OPSB had not established a process to ensure
performance evaluations were based on measurable standards or that their
content met legal requirements. Specifically, OPSB had not established
procedures for reviewing State agency completed evaluations and related
position descriptions to ensure they included measurable standards and
certain key elements, such as specific tasks to be achieved during the next
rating period, as required by law. For example, our test of end-of-cycle
evaluations for the six months ended June 30, 2016 for 189 employees from
four large agencies found that for 114 employees (60 percent), the
evaluations lacked specific tasks to be achieved during the next rating period.
In addition, OPSB did not clearly communicate training expectations for those
State agency employees in supervisory and managerial positions who are
responsible for preparing performance evaluations. Further, OPSB did not
require agencies to maintain records of employees in those position receiving
training. In addition, oversight was insufficient because OPSB did not track
nor require agencies to report whether supervisory employees had received
mandatory training on the performance evaluation process, as required by
State law.
For example, our on-site review of four agencies subject to DBM authority with
large workforces identified one agency, which had approximately 325
supervisors or managers as of July 2017, that was unaware that PEP training
was mandatory and consequently, had not provided this required training.
Although the remaining three agencies had established PEP training programs
for their supervisors and managers totaling approximately 4,200 as of July 17,
2017, we were unable to determine the extent to which those individuals had
been trained. According to SPS records, as of July 17, 2017, there were
approximately 7,400 employees in supervisory or managerial positions
Statewide, who should be subject to this training.
18

--- Page 21 ---
In addition, OPSB had not developed approaches to evaluate the
effectiveness of the PEP and training courses and had not formally sought
relevant feedback from employees or supervisors. Such feedback could be
helpful in identifying any needed enhancements to ensure the PEP results in a
meaningful and honest exchange about employee performance. Between
20.8 and 27.7 percent of the individuals who participated in our survey of
employees and supervisors indicated that they did not believe PEP was
achieving its desired outcomes, including facilitating communication between
supervisors and employees, or was effective and valuable to employee
development. In addition, 18.0 percent of the supervisors and managers
expressed concern about the usefulness of training. Finally, certain provisions
of the PEP Guidelines may hamper the effectiveness of the PEP since
evaluators are advised they need not formally rate employee performance for
each essential job function within the position descriptions, if evaluators rate
overall work quality is satisfactory or better. Consequently, employees may
not be expressly told what specific functions met targets and which did not.
Finally, our review of five agencies (each with over a thousand employees)
consisting of four agencies subject to DBM authority and one independent
agency3 disclosed that three (DPSCS, MDH, and MDOT) were not using
available personnel system reports or other means to monitor the completion
of performance evaluations. For DPSCS, MDH, and MDOT we noted, through
a review of documentation supporting the APR and testing, that 31.3, 15.6,
and 13.2 percent, respectively, of their employees had not received
evaluations as reported in the 2016 APR. Conversely, we found that the two
agencies that used available system reports to track completion of
evaluations (DHS and DNR) had each completed evaluations for over 96
percent of their employees. Nevertheless, none of the five agencies reviewed
had established controls over the recording of evaluation data in SPS or their
internal personnel systems to ensure that all evaluations given were
accurately recorded.
None of the five agencies reviewed had effectively monitored the content of
end-of-cycle or annual performance evaluations given to employees for
compliance with legal requirements or policy. Specifically, numerous
performance evaluations tested that were given to employees were not fully
completed as required. In some cases, position descriptions with measurable
performance standards were also not maintained. For example, for the four
agencies in the State Personnel Management System, our tests determined
3 The five agencies were the Department of Human Services (DHS), Department of Natural
Resources (DNR), Department of Public Safety and Correctional Services (DPSCS),
Maryland Department of Health (MDH), and Maryland Department of Transportation
(MDOT). MDOT has an independent personnel system and is not subject to DBM authority.
19

--- Page 22 ---
that evaluations for 114 of the 189 employees (60 percent), with end-of-cycle
evaluations for the period ended June 30, 2016, lacked specific tasks to be
achieved during the next rating period as required, including 67 employees
who had the same omission for the evaluation period ending June 30, 2015.
Consequently, there was a lack of assurance that these employees were
notified of expectations for the upcoming rating period, which could help
elevate employee performance.
Furthermore, none of the five agencies tested had a process to track whether
each of their supervisors had received performance appraisal training, either
from OPSB, an in-house training program, or online through DBM’s Learning
Management System. State law requires that each employee receive training
in the performance appraisal process’ methods and procedures. This
condition could be a factor influencing the aforementioned incomplete
employee performance evaluations.
20

--- Page 23 ---
Findings and Recommendations
Objective 1
Assess the Department of Budget and Management (DBM) –
Office of Personnel Services and Benefits’ (OPSB’s) Efforts to
Ensure Employee Performance Evaluations Are Given and the
Results Are Accurately Reported
Finding 1
Many employees had not received required evaluations during a five-year
period and OPSB had not established a comprehensive strategy to improve
agency compliance or ensure agencies monitored their efforts.
Analysis
Many employees of the agencies under DBM’s authority were not evaluated
and OPSB lacked a comprehensive strategy to improve agency compliance
with evaluation requirements in State law. Furthermore, OPSB had not
established requirements that agencies monitor the recordation and
completion of evaluations using the State Personnel System (SPS) or other
internal tracking mechanisms.
Strategy to Improve Agency Compliance
According to the Annual Personnel Reports (APRs) for fiscal years 2012
through 2016, agencies reported that between 83.9 to 90.8 percent of their
State employees received performance evaluations. Conversely, an average
of approximately 5,600 employees annually did not receive an evaluation
during that five-year period. For example, the annual report as of June 30,
2016, indicated that 37,999 (83.9 percent) employees received an
evaluation and 7,272 (16.1 percent) employees did not. We tested the
evaluation documentation for a random statistical sample of 131 employees
who were employed by the State in agencies included in the June 30, 2016
annual report and determined the overall reported percentage of employees
evaluated was reasonably accurate, based on OPSB’s report preparation
methodology (see Finding 2).4
Although OPSB monitored agency self-reported information regarding the
number of employees who had not received required end-of-year evaluations,
4 Specifically, our probability sampling was based on 90 percent confidence, expected error
occurrence rate of 14 percent based on pre-testing, and precision of 5 percent.
Consequently, based on the results of our sample of 131 employees, we are 90 percent
confident that evaluations were documented for between 79.6 and 89.9 percent of the
State employees subject to this requirement.
21

--- Page 24 ---
in conjunction with the preparation of the APR, it had not established a
comprehensive strategy to improve agency compliance. For example, OPSB
had not established a process to routinely follow-up with agencies who
reported high numbers of evaluations that were not completed by notifying
management that their appointing authorities had failed to substantially
complete required evaluations. As of January 2017, OPSB had not sent any
formal notices of noncompliance to agencies since August 2013. Before
August 2013, OPSB advised agencies when they failed to “substantially
complete” (defined by OPSB as at least 85 percent) the required number of
evaluations.
During the APR preparation process, OPSB staff sent emails to agency human
resources personnel with the purpose of encouraging the agencies to
complete and report outstanding evaluations to OPSB as soon as possible.
However, no attempt was made to identify the underlying reasons for low
reported completed evaluation numbers and develop corrective actions.
Guidance for Monitoring Evaluation Completion
OPSB’s PEP Guidelines did not specify that agency managers designated as
appointing authorities should use SPS to record all employees’ evaluation
results and track the employees who had not been evaluated for follow-up
purposes. However, our review of the evaluation procedures for four agencies
with large employee populations as of June 30, 2016 disclosed that each had
a process to record certain evaluation information in SPS; generally, the time-
period covered by the evaluation and the overall employee rating. We also
determined that the two agencies with the highest annual percentage [99.5
percent for Department of Human Services (DHS) and 96.5 percent for
Department of Natural Resources (DNR)] of evaluated employees had
established internal evaluation tracking procedures using available reports in
SPS. These system reports were used to identify which employees had not
been evaluated to notify their supervisors and, in light of the high evaluation
completion percentages, demonstrates the usefulness of using SPS for
tracking purposes. Conversely, the other two agencies [Department of Public
Safety and Correctional Services (DPSCS) and Maryland Department of Health
(MDH)] which had not established such tracking mechanisms had lower
evaluation percentages (ranging from 68.7 percent to 84.4 percent) for the
year ended June 30, 2016 (see Finding 6).
Identifying Trends
In addition, OPSB had not attempted to use SPS to compile and summarize
evaluation data to identify trends that could help target its follow-up efforts.
Our analysis of evaluation ratings in SPS determined that as of January 23,
2017 no evaluation ratings had been reported for at least 2,500 specific
22

--- Page 25 ---
employees since the system was implemented in November 2014, including
391 employees with annual salaries exceeding $100,000. Furthermore,
OPSB had not developed an SPS agency overdue evaluations report to
monitor agency compliance efforts throughout the year.
Recommendation 1
We recommend that OPSB
a. develop comprehensive strategies for addressing agency non-compliance
with employee performance evaluation requirements;
b. amend existing PEP Guidelines to specify that all applicable Executive
Branch agencies use SPS to record evaluations and track evaluation
activity, as well as to institute appropriate internal follow-up to improve
evaluation completion performance; and
c. monitor SPS evaluation data to identify trends to target follow-up efforts.
Finding 2
OPSB did not disclose certain information in the APR needed to better
interpret and clarify the performance evaluation results. In addition, complete
records supporting the APR were not maintained and controls were not
established to ensure the accuracy of SPS data used to compile the APR.
Analysis
OPSB did not disclose certain information regarding the methodology used to
prepare the APR, excluded certain agencies’ data, and combined the
individual results of many other agencies. Furthermore, automated processes
were not developed to support the APR results; instead, OPSB manually
compiled the evaluation data without establishing recordkeeping controls.
Although, as noted in Finding 1, OPSB had not established a policy requiring
the recordation of all evaluations in SPS, when completed evaluations were
recorded, we found there were no procedures in place to ensure that they
were accurately recorded in SPS by State agency personnel. These issues can
affect the interpretation of the APR information and the integrity of the
reported data.
Report Preparation Methodology
 The APR did not contain a complete description of the methodology used
to report evaluation results and, therefore, could be subject to
misinterpretation. The APR did not state that the performance evaluation
data in the APR only reflected evaluations, both informal mid-cycle and
comprehensive end-of-cycle, that were due for the six-month period ended
June 30th rather than provide data for the entire fiscal year. For example,
the APR did not disclose the number of employees who had received both
23

--- Page 26 ---
the informal and comprehensive end-of-cycle evaluations during the fiscal
year reported even though this information was available in SPS.
Our review of SPS records for the PEP cycle ending June 30, 2016
disclosed that 48 percent of 29,384 employees (this excludes the
Maryland Department of Transportation (MDOT) which has a different
evaluation system) received mid-cycle evaluations since their hire dates
were between January 1st and June 30th while the remaining 52 percent of
employees received end-of-cycle evaluations as of June 30th.
Given the requirement that employees are to receive both evaluations in a
year, it may be more informative to report the numbers of employees who
received: (1) only the informal mid-cycle evaluation; (2) only the end-of-
cycle evaluations; and (3) those employees who received both evaluations
as required during the reporting year. This additional information could
present a different perspective. For example, based on our Statewide
statistical sample of fiscal year 2016 end-of-cycle evaluations for the 131
employees, we can state with a 90 percent confidence level that the
completion rate for such evaluations was between 88 and 96 percent for
employees during fiscal year 2016.
 OPSB did not report performance evaluation statistics for certain agencies
with independent personnel systems in the APR as required by law. For
example, the APR issued by OPSB did not include performance evaluation
results for the Maryland Stadium Authority, Baltimore City Community
College (BCCC), Morgan State University, or St. Mary's College of Maryland.
Although the APR disclosed that the BCCC evaluation data was excluded,
the other missing agencies were not mentioned. Nevertheless, there does
not appear to be legal basis for excluding any of these agencies from the
report. State Personnel and Pensions Article, Title 4, Subtitle 3, of the
Annotated Code of Maryland requires that the annual personnel report
should include information about all Executive Branch employees,
including employees of agencies with independent personnel systems, but
excluding the University System of Maryland. Per our review of Central
Payroll Bureau payroll data, there were 2,138 employees of these four
agencies in calendar year 2016 for which performance evaluation results
were excluded from the APR.
OPSB management advised us that these agencies were not included
based on discussions with the Department of Legislative Services’ Office
of Policy Analysis when the legal requirement for the APR was established
24

--- Page 27 ---
in 1996. OPSB had not obtained advice from its legal counsel to
determine whether excluding these agencies was consistent with the law.
 The format for the 2015 and 2016 APR did not provide needed specificity
for some State agencies, including calculated compliance rates, because
many agencies, some with low evaluation completion rates, were grouped
together in a miscellaneous category in the APR rather than listed
separately.
For example, the June 2015 APR combined into one category 40 agencies
(consisting of 5,682 employees or 13 percent of the total employees) of
which 22 agencies had employed from 50 to 1,018 employees and had
evaluation completion percentages ranging from zero to 100 percent.
These 40 agencies were not considered principal agencies, which were
separately listed in the APR, despite the fact that the size of the workforce
for many of the 40 agencies was greater than some that were separately
listed. As a result, it was not readily apparent that for June 2015 there
were, for example, 7 agencies employing from 52 to 585 employees that
had evaluation completion percentages ranging from 0 (for 3 agencies) to
63 percent (for 3 agencies) that were not separately disclosed in the APR.
Evaluation Data Compilation Process
 Although performance evaluation information was recorded by certain
State agencies in SPS, OPSB had not developed the automated capability
to compile such evaluation data for the final APR report and retain an
historical summary record of this information as of the end of the reporting
period. The SPS data is being continually updated, so available SPS
reports with evaluation information could not be used to verify the APR
report because these SPS reports only listed the most recent evaluations
completed. As a result, evaluation totals for preceding dates (such as the
number of evaluations recorded in a previous year) were not readily
available. SPS also could not be used to identify any modifications made
after the reporting period was closed out in SPS (for example, the
November following the June 30th reporting period) pertaining to
evaluations given during that period. Consequently, manual records were
prepared to account for modifications after the SPS closeout date to
provide more accurate information for the APR.
 The manual records that were maintained by OPSB did not provide a
complete audit trail of the original evaluation information obtained from
SPS and the subsequent modifications that were made to prepare the
APR. Consequently, the underlying data supporting the APR (that is, the
25

--- Page 28 ---
specific employees who received evaluations during the reporting period)
could not be recreated.
SPS data, in the form of agency employee and evaluation rating category
totals, were manually compiled by an OPSB employee and recorded in a
spreadsheet. The evaluation completion counts in this spreadsheet were
edited multiple times based on agency emails and telephone
conversations, without OPSB obtaining verification or related support
(such as screen printouts). Furthermore, the spreadsheets were printed
and manually adjusted with written notations then updated and reprinted,
but not all versions were retained on file.
For example, we noted where adjustments were made to increase the
fiscal year 2016 completed evaluation totals in the spreadsheet for three
State agencies (DPSCS – 1,051, Commerce – 127, and DBM - 38) by a
collective 1,216. The largest adjustment was for DPSCS, which increased
the number of employees rated by 1,051 (an increase from 5,518 in the
initial draft to 6,569 for the final report). However, as of October 28,
2016, the SPS only listed 5,400 DPSCS employees as having received
completed evaluations, a difference of 1,169 from the final total published
in the 2016 APR. OPSB personnel advised us that the difference was due
to employee PEP ratings that were purportedly given but never recorded in
SPS (as noted in Finding 1, there was no policy requiring agencies to
record evaluations in SPS).
SPS Data Verification Process
 OPSB had not established procedures to ensure the accuracy of the
evaluation information entered into SPS by State agency personnel and
used to prepare the APR. OPSB did not verify that agencies properly
recorded in SPS the applicable information from paper copies of
evaluations, or more importantly, that an evaluation was actually prepared
when so indicated in SPS. For example, OPSB did not require State
agencies to provide copies of randomly selected completed evaluations to
OPSB on a test basis to support SPS data they entered.
In addition, OPSB did not require State agencies to establish controls to
ensure all evaluations given were properly and accurately recorded in SPS.
For example, our review of five large agencies disclosed that none of these
agencies had established an independent verification of the accuracy of
evaluation ratings entered in SPS. Furthermore, these agencies had not
established data input control records that could be used to perform the
verifications.
26

--- Page 29 ---
Our review of the evaluation data for 521 employees randomly selected
from four large agencies using SPS disclosed many recordation
discrepancies, as shown in Table 2. Specifically, we found 94 instances in
which SPS indicated that either a mid-cycle or end-of-cycle evaluation was
completed but the agency could not locate the evaluation documentation,
or evaluation documentation was provided but not reflected in SPS.
Table 2
Results of OLA Test of Evaluation Recordation in SPS
Evaluations for the Six Months Ended June 30, 2016
Evaluation Documentation
Employees Recorded in SPS Provided but Total
Department
Tested but Documentation Evaluation Not Discrepancies
Not Provided Recorded in SPS
DHS 42 1 0 1
DNR 31 0 0 0
DPSCS 224 28 29 57
MDH 224 24 12 36
Total 521 53 41 94
Source: OLA test of 521 employees randomly selected from 4 large agencies
Recommendation 2
We recommend that OPSB
a. disclose the methodology used to prepare the APR and consider reporting
evaluation data for an entire fiscal year;
b. obtain and report employee performance evaluation results for all
Executive Branch agencies in the APR as required by law;
c. expand the number of agencies individually listed on the APR (for
example, individually list principal agencies and other agencies with
greater than 50 employees);
d. develop an automated capability to compile evaluation data for the
preparation of the APR to eliminate the need for manual records,
otherwise establish appropriate manual controls and recordkeeping to
support APR data;
e. establish procedures to verify that agencies accurately recorded
evaluations in SPS; and
f. require agencies to establish controls to ensure all evaluations given
were properly and accurately recorded in SPS.
27

--- Page 30 ---
Objective 2
Assess OPSB’s Efforts to Ensure Completed Performance
Evaluations Contain Required Content, Supervisors Receive
Mandatory PEP Training, and the Overall Purpose of the PEP Was
Being Achieved
Finding 3
OPSB had not established a process to ensure performance evaluations were
based on measurable standards and their content met legal requirements.
Analysis
OPSB had not established a process to ensure performance evaluations were
based on measurable standards and their content met legal requirements.
Specifically, OPSB had not established procedures for reviewing completed
evaluations and related position descriptions to ensure they included
measurable standards and certain key elements, such as specific tasks to be
achieved during the rating period, as required by law.
Of the 112 employees in our Statewide statistical sample of employees
subject to DBM oversight (that is, excluding 19 MDOT employees from the
131 sample size), we found that for many of the employees, position
descriptions and the end-of-cycle performance evaluations forms lacked
required elements.
 For 12 of the 112 employees (11 percent), agencies had not established
position descriptions (via Form MS-22) with measurable performance
standards as required. Specifically, the position description forms either
had a standards area that was blank or had no measurement criteria.
State law and the PEP Guidelines require agencies to establish written
position-specific performance standards that are observable, measurable,
and objective to place the employee on notice as to what is required. An
example of such a measure, as provided in the PEP Guidelines, would be
as follows: “at least 85% of customers surveyed rated the employee
“satisfactory” or better on application disposition.” According to the
Guidelines, a standard should be established for each essential job
function listed on the position description. Without these standards, the
position expectations may not be conveyed before the rating period and
available to objectively evaluate employees at the end of that period.
There appears to be an inconsistency regarding the establishment of
performance standards in position descriptions as discussed in the PEP
Guidelines and its instructions for completing the MS-22. According to the
28

--- Page 31 ---
PEP Guidelines, “…position-specific performance standards should place
the employee on notice as to what is required to be rated ‘Outstanding’,
“Satisfactory’, and ‘Unsatisfactory’ ” whereas the instructions only require
the standards needed to meet satisfactory. Most of the position
descriptions we reviewed did not establish standards for all 3 categories,
which would be helpful to support an employee’s overall rating.
 For 50 of the 112 employees subject to DBM authority with end-of-cycle
evaluations for the six months ended June 30, 2016, over half of the
evaluations lacked specific tasks to be achieved during the next rating
period, as required. As shown in Chart 1, 27 of the 50 employees (54
percent) lacked written specific tasks to be achieved, which if completed
could help improve employee productivity, work quality, and/or behavior.
Although 9 of these employees were rated ‘satisfactory’, with the
remainder rated ‘outstanding’, State law stipulates that a required
element of end-of-cycle evaluations is establishing (and providing
employees with) specific written tasks and indicators. These tasks and
indicators are to be based on measurable and objective standards that
can be evaluated on an outcome that the employee needs to accomplish
in order to meet the overall objectives of the position.
Chart 1
June 30, 2016 Performance Evaluations
Statewide Sample Test Results
50 Employees With End‐of‐Cycle Evaluations
27 employees (54%) with end‐
of‐cycle evaluations that
54%
lacked written specific tasks to
No Specific Tasks
be achieved during the next
Written
rating period as required,
which included 9 employees
rated Satisfactory and 18 rated
Outstanding.
23 employees (46%) with end‐
of‐cycle evaluations that had
46%
specific tasks to be achieved
Specific Tasks Written
written on evaluation.
Source: OLA testing
29

--- Page 32 ---
Neither the PEP Guidelines or the formal manager and supervisor training
materials provide any instructions to help evaluators meet this requirement.
Although the evaluation forms have a designated location for evaluators to
record such tasks, no guidance is offered to explain how these tasks, for
example, relate to position descriptions performance standards and would
improve employee productivity.
As noted later in Finding 7, we also conducted tests of evaluations issued by
five individual state agencies with significant numbers of employees for
adequacy of content. These tests also disclosed that position descriptions
and the end-of-cycle performance evaluations forms often lacked required
elements similar to the results of our statewide test. For example, of the 521
employees randomly selected from the four agencies under DBM’s authority,
11 percent lacked measurable performance standards in their position
descriptions.
Furthermore, as shown in Chart 2 on the following page, for 114 of the 189
employees5 (60 percent) from the four agencies with end-of-cycle evaluations
for the six months ended June 30, 2016, the evaluations lacked specific tasks
to be achieved during the next rating period, as required. Consequently, there
was a lack of assurance that these 114 employees (66 who were rated
‘satisfactory’, with the remainder rated ‘outstanding’) were notified of
expectations for the upcoming rating period, which could help improve
employee productivity, work quality, and/or behavior.
5 The 189 employees represent a subset of the 521 randomly selected employees tested
from the four agencies under DBM’s authority who received end-of-cycle evaluations at
June 30, 2016. The remaining 332 employee from the original test either did not have an
evaluation on file for the period or received an interim evaluation.
30

--- Page 33 ---
Chart 2
June 30, 2016 Performance Evaluations
Agency Sample Test Results
189 Employees with End‐of‐Cycle Evaluations
114 employees (60%) with end‐of‐
60% cycle evaluations that lacked written
No Specific Tasks specific tasks to be achieved during
Written the next rating period as required,
which included 66 employees rated
Satisfactory and 48 rated
Outstanding.
40% 75 employees (40%) with end‐of‐
Specific Tasks cycle evaluations that had specific
Written tasks to be achieved written on
evaluation.
Source: OLA testing
Recommendation 3
We recommend that OPSB
a. establish procedures for reviewing completed evaluations and position
descriptions, at least on a test basis, for sufficiency of content;
b. ensure the applicable agencies are notified of deficiencies and take
appropriate corrective actions;
c. enhance and clarify the PEP Guidelines to require the establishment of
measurable performance standards in position descriptions and to require
that end-of-cycle evaluations include written specific tasks to be achieved
by employees during the next rating period as required by State law; and
d. ensure consistency in its PEP Guidelines and MS-22 instructions.
Finding 4
OPSB did not clearly set the expectations for required mandatory PEP-related
training for supervisory and managerial employees, require the maintenance
of agency-based training records, or monitor agency training efforts.
Analysis
OPSB did not clearly communicate training expectations for those in
supervisory and managerial positions who are responsible for preparing
performance evaluations. Furthermore, OPSB did not require agencies to
31

--- Page 34 ---
maintain records of those receiving training. In addition, OPSB oversight was
insufficient because it did not track nor ask agencies to report whether
supervisors had received mandatory training on the performance evaluation
process as required by State law. As of July 17, 2017, there were
approximately 7,400 employees in supervisory or managerial positions
statewide under SPS who should be subject to this training.
State law requires each (agency) supervisor to attend mandatory training by
DBM on the methods and procedures required in the performance appraisal
process. We were advised by OPSB management that due to a reduction in
staffing effective fiscal year 2005, OPSB discontinued previous efforts to
provide the required in-person classroom training to every agency supervisor.
Consequently, in an acknowledgement of its inability to comply with State law,
OPSB’s Employee and Labor Relations Division (ELRD) established an
alternative process. Specifically, ELRD attempts to provide up to two in-
person training courses annually with the goal of training at least one
management employee at each agency, who, in-turn, should train all other
supervisory personnel at their agency on the PEP requirements. OPSB has
also made the PEP training presentation available online for agency
supervisors on its website and through their Learning Management System,
which could satisfy the aforementioned requirements of State law.
However, OPSB did not communicate its expectation that employees who
attend its in-person PEP training courses, which includes reviewing the PEP
purpose and requirements, to train all supervisory personnel at their agencies.
There was no mention of this expectation in its written course materials or on
its website. Without formal training, there is an increased risk that agency
supervisors and managers, who did not attend an in-person course, will not
properly complete required performance evaluations in order to formally
communicate expectations and job performance with employees.
Our on-site review of four agencies subject to DBM authority with large
workforces identified one agency (Department of Natural Resources) that was
unaware of DBM’s expectation that its employees who attended the in-person
PEP training courses were to train all the other supervisory personnel at their
agency. Consequently, this agency had not provided this required training to
its supervisors or managers, which totaled approximately 325 as of July 17,
2017.
Although the remaining three agencies had established PEP training programs
for their supervisors and managers totaling approximately 4,200 as of July 17,
2017, we were unable to determine the extent to which those individuals had
been trained. Specifically, OPSB did not require agencies to maintain training
32

--- Page 35 ---
records nor did OPSB make any such inquiries to determine whether the
training requirements in State law had been met. We were advised by two of
the three aforementioned agencies that training records were not maintained
in a manner to readily identify whether all supervisors had received PEP
training (see finding 8).
Recommendation 4
We recommend that OPSB ensure compliance with State law requiring it to
provide PEP training to agency supervisors. Specifically, OPSB should
a. clearly communicate its training expectations to state agencies, including
the need to ensure all supervisors and managers are properly trained;
b. require state agencies to maintain detail PEP records to track PEP training
provided to each supervisor and manager to substantiate the
requirements of State law have been met; and
c. monitor state agency PEP training efforts, including employee
attendance/participation by requiring periodic reports on training
activities.
Finding 5
OPSB had not developed approaches to formally evaluate the effectiveness of
the PEP as well as training courses for managers and supervisors.
Analysis
OPSB had not developed approaches to formally evaluate the effectiveness of
the PEP and training courses. For example, OPSB had not formally sought
feedback from employees, including those managers who participated in its
training course, or those who received such instruction from their managers or
via the online course. Such feedback could be helpful in identifying any
needed enhancements to ensure the process results in a meaningful and
honest exchange about employee performance and leads to performance
improvements, when warranted.
Some individuals who responded to our survey indicated that they did not
believe PEP was achieving its desired outcome and some supervisors and
managers expressed concern about the training. The results of our survey
disclosed the following:
Survey Results on PEP
 Eighteen of the sixty-five supervisors (28 percent) and eleven of the fifty-
three employees (21 percent) surveyed who responded did not believe
that the PEP accomplished its stated purpose of facilitating
33

--- Page 36 ---
communication between supervisors and employees regarding
expectations and job performance.
 Eleven of the fifty-three employees (21 percent) surveyed did not believe
the PEP process was effective and valuable to employee development.
For example, written comments from employees and supervisors
surveyed, described the PEP as "meaningless" and the PEP form as a
"flawed assessment tool."
 Survey participants also responded that the three rating categories were
too broad (one employee), the PEP documentation often did not reflect
employees’ actual job duties (two employees), there was a lack of
correlation between the employees’ actual performance and their rating
(ten employees), and there was a lack of incentives for outstanding
performance (one employee).
Survey Results on Training
 Eleven of the sixty-one managers or supervisors (18 percent) who
responded did not find the training to be a useful tool to aid in conducting
evaluations with their employees. Written comments from five of these
eleven supervisors indicated that the training was “generic,” lacked details
on how to actually complete the evaluation form, or did not address how to
deal with problem employees.
 Four managers or supervisors responded that they had not received
training so they could not comment on training usefulness.
Further Observation About PEP
Based on our review of PEP, we believe OPSB should reconsider a particular
aspect of its PEP guidance as it relates to rating employee work quality, which
we believe compromises the effectiveness of the process.6 PEP Guidelines
specify that evaluators need not formally rate employee performance for each
essential job function within the position descriptions if evaluators rate overall
work quality as satisfactory or better on the end-of-cycle evaluations.
Consequently, employees may not be expressly told what specific functions
met targets and which did not. During our testing, we noted that evaluations
often did not list applicable job functions with separate ratings under the
category of work quality.
6 There are three different evaluation forms (one each for non-supervisory, supervisory, and
management employees). A copy of the non-supervisory evaluation form has been included
in Exhibit 3.
34

--- Page 37 ---
In this situation, there is an increased risk that raters will subjectively
conclude individuals performed satisfactorily without determining the extent
to which objective targets set in position descriptions have been met. The
failure to perform this exercise would seem to negate the purpose of
establishing objective targets except for unsatisfactory ratings, which are rare.
According to the fiscal year 2016 APR, only 0.3 percent employees (146)
received an unsatisfactory rating.
Furthermore, the PEP Guidelines do not seem to recognize the possibility that
while overall work quality may be appropriately deemed satisfactory, there
could be functions that need to be improved and should be communicated to
help raise overall performance and employees’ contributions to their agency
mission.
Recommendation 5
We recommend that OPSB
a. develop approaches, such as employee surveys, for evaluating the
effectiveness of the PEP and the OPSB training; and
b. reassess the appropriateness of PEP Guidelines pertaining to evaluating
employee work quality for those rated satisfactory or better.
Objective 3
Assess Selected Agencies’ Procedures for Monitoring the Proper
Completion of Performance Evaluations for Their Employees and
Providing Related Training to Supervisors
Finding 6
Certain agencies that were not using available personnel system records to
monitor completion of performance evaluations had many employees who
were not evaluated. None of the five agencies reviewed had established
controls over the recording of evaluation data in the personnel systems.
Analysis
Our review of five agencies with each over a thousand employees – four
subject to DBM authority and one independent agency (MDOT) – disclosed
that three were not using available personnel system reports (that is, either
SPS or MDOT’s Human Resources Information System (HRIS)) or other means
to monitor the completion of performance evaluations. Furthermore, none of
the five agencies reviewed had established controls over the recording of
evaluation data in the personnel systems to ensure all evaluations given were
accurately recorded.
35

--- Page 38 ---
DPSCS and the MDH, while recording evaluation results in SPS, had not
established a process to use available SPS reports or other suitable means to
routinely identify and notify supervisors of employees who had not received
required evaluations. Furthermore, MDOT’s Office of the Secretary – Human
Resources unit was not routinely using the department’s personnel system to
monitor evaluations completed by its business units and identify employees
who had not been evaluated. Rather, the business units were responsible for
ensuring evaluations were completed as required without any effective central
monitoring.
Consequently, two of the three departments had many employees (16 to 31
percent) who had not received evaluations as reported in the 2016 APR and
confirmed by our tests. Conversely, our audit disclosed that the two agencies
(DNR and DHS) that used available SPS reports to track completion of
evaluations had completed evaluations for over 96.5 and 99.5 percent of
their employees, respectively.
Evaluations Completed
 According to the 2016 APR, DPSCS only completed mid-cycle or end-of-
cycle performance evaluations due on June 30th for 6,569 of its 9,566
regular employees (69 percent), indicating that the remaining 2,997
employees (31 percent) were not evaluated. (Evaluations that were due
on December 31st were not reported in the APR.) However, our test of the
evaluation documentation for a random statistical sample of 224 DPSCS
employees suggests that fewer employees may have received ratings than
what was reported during the period ended June 30, 2016. Our testing
found evaluation documentation for only 59 percent of the employees
tested. If this condition is not just missing documentation, but a failure to
conduct an evaluation, then from this statistical sample, we are 95
percent confident7 that evaluation documentation would be missing for at
least 35 percent of DPSCS employees for the period ending June 30,
2016.
 According to the 2016 APR, MDH completed mid-year or end-of-cycle
performance evaluations for 6,724 of its 7,967 regular employees (84
percent), indicating that the remaining 1,243 employees (16 percent)
7 Probability sampling was performed based on 90 percent confidence, an expected error
occurrence rate of 30 percent based on pre-testing, and precision of 5 percent. Another
way of expressing the results, beyond the one-sided projection in the body of the finding, is
that based on the results of our sample, we are 90 percent confident that evaluation
documentation would be missing for between 35.7 percent and 46.4 percent of the DPSCS
employees subject to this requirement.
36

--- Page 39 ---
were not evaluated. This result was generally confirmed by our random
statistical sample of 224 MDH employees.
 According to the 2016 APR, MDOT completed annual performance
evaluations for 5,091 of its 5,868 regular employees (87 percent),
indicating that the remaining 777 employees (13 percent) were not
evaluated. Our test of the evaluation documentation for a random
statistical sample of 70 MDOT employees suggests, however, that more
employees may have received evaluations during calendar year 2015 than
what was reported. Our testing found evaluation documentation for 97
percent of the employees tested, which means we are 95 percent
confident8 that that no more than 6 percent of evaluations would be
missing for the period ending December 31, 2015.
Our test results also suggest that many completed evaluations may not
have been recorded in the HRIS, which should have been used to compile
MDOT’s data for the APR. However, we could not confirm this because,
similar to Finding 2 regarding APR data for agencies using SPS, MDOT did
not maintain documentation to support the evaluation numbers it reported
to OPSB. That is, a file listing all 5,091 employees who reportedly received
evaluations was not available. MDOT prepares annual performance
evaluations on a calendar year basis that are reported in the subsequent
fiscal year’s APR by DBM. Therefore, the fiscal year 2016 APR reflects
MDOT employee evaluations from calendar year 2015.
Evaluation Data Recordation Controls
Our reviews of the processes used by the five agencies for recording
evaluation data into the applicable personnel system disclosed that none of
the agencies established effective input controls to ensure all completed
evaluations had been accounted for and accurately recorded.
We noted that, for the four agencies using SPS, paper evaluations received by
the human resource offices for processing were not batched and verifications
were not performed to ensure that all such evaluations, and the data thereon,
were properly recorded. Furthermore, the various MDOT business units,
which were responsible for recording evaluations in HRIS, also did not
establish effective document control and verification procedures. Four of the
five MDOT business units had not established such procedures whereas the
other administration represented that verifications were performed but
supporting documentation was not maintained.
8 Probability sampling was performed based on 90 percent confidence, an expected error
occurrence rate of 7 percent based on pre-testing, and precision of 5 percent, and we used
a one-sided projection to present our results at 95 percent confidence.
37

--- Page 40 ---
Consequently, the lack of proper controls could impair the ability of the
agencies to effectively monitor compliance with the requirements established
by law and policy.
State Personnel and Pensions Article Title 7, Subtitle 5, of the Annotated Code
of Maryland requires each appointing authority for agencies within the State
Personnel Management System to ensure that each employee is evaluated at
six-month intervals. Further, Code of Maryland Regulations state that MDOT
employees shall receive a written appraisal at least annually. Effective
monitoring of evaluation data, which has been subject to effective recordation
controls is necessary to ensure compliance with the statute and regulations.
Recommendation 6
We recommend that
a. DPSCS, MDH, and MDOT establish procedures, such as routine monitoring
of personnel system data, to ensure employee performance evaluations
are completed as required by statute or regulation;
b. all five agencies establish processing controls to ensure all completed
evaluations had been accounted for and accurately recorded in the
applicable personnel system; and
c. MDOT maintain documentation to support evaluation data reported
annually to OPSB.
Finding 7
None of the five agencies reviewed had effectively monitored the content of
performance evaluations given to employees for compliance with legal
requirements or policy.
Analysis
None of the five agencies reviewed had effectively monitored the content of
end-of-cycle or annual performance evaluations given to employees for
compliance with legal requirements or policy. Specifically, numerous
performance evaluations tested that were given to employees were not fully
completed as required. In some cases, position descriptions with measurable
performance standards were also not maintained.
State law pertaining to employees under the State Personnel Management
System (SPMS) requires that performance evaluations include specific tasks
to be achieved during the next rating period, and employee position
descriptions must have measurable performance standards. In addition,
MDOT human resources policy requires that each employee receive a
development plan or an improvement plan as part of the evaluation. Finally,
38

--- Page 41 ---
this MDOT policy and the related supervisor’s booklet require that evaluations
include performance ratings for general factors, job specific factors, and
leadership factors, which are to be initially documented on what is known as a
criteria assessment sheet (see further details below).
Agencies in SPMS
For the four agencies in SPMS, our tests determined that evaluations for 114
of the 189 employees (60 percent), with end-of-cycle evaluations for the
period ended June 30, 2016, lacked specific tasks to be achieved during the
next rating period as required. In addition, for 96 of the 166 employees (58
percent) with end-of-cycle evaluations for the period ended June 30, 2015,
the evaluations lacked specific tasks to be achieved, including 67 employees
with this omission in both years. Consequently, there was a lack of assurance
that these employees were notified of expectations for the upcoming rating
period, which could help elevate employee performance. Our results are
detailed in Table 3 on the next page.
Furthermore, as shown in Table 4 on page 41, our tests determined that
position descriptions with measurable performance standards had not been
established for 55 of 521 employees (11 percent) selected from the four
agencies for the period ended June 30, 2016. Without these standards, the
position expectations may not be conveyed before the rating period and
available to evaluate employees objectively at the end of that period. Our
results are detailed in Table 3.
39

--- Page 42 ---
Table 3
OLA Test Results
Agency End-of-Cycle Evaluations With or Without Specific Tasks to be
Achieved
June 2015 and 2016 Rating Periods
Both
June 2015 Rating Period June 2016 Rating Period
Periods
Specific Specific Total Percent Specific Specific Total Percent Specific
Tasks Tasks Not Tested Without Tasks Tasks Not Tested Without Tasks Not
Agency Included Included End Cycle Tasks Included Included End Cycle Tasks Included
PEPs PEPs
DPSCS 26 34 60 57% 23 46 69 67% 25
MDH 34 45 79 57% 37 50 87 57% 30
DHS 4 11 15 73% 10 12 22 55% 6
DNR 6 6 12 50% 5 6 11 55% 6
Totals 70 96 166 58% 75 114 189 60% 67
40

--- Page 43 ---
Table 4
OLA Test Results
Number of Agency Evaluations Tested With or Without Measurable
Performance Standards
Included for the Applicable Employee’s Position Description
June 2015 and 2016 Rating Periods
June 2015 Rating Period June 2016 Rating Period Both Periods
Performance Performance Performance Performance Performance Performance
Total Total Total
Standards Standards Standards Standards Standards Standards
Agency Included Not Included Tested Included Not Included Tested Included Not Included Tested
DPSCS 205 14 219 209 15 224 205 14 219
MDH 177 27 204 192 32 224 174 27 201
DHS 38 3 41 39 3 42 38 3 41
DNR 27 4 31 26 5 31 26 4 30
Totals 447 48 495 466 55 521 443 48 491
MDOT
Our test determined that for 35 of the 70 MDOT employees (50 percent) the
annual appraisals for the year ended December 31, 2015 did not include an
employee development plan as required. Although the overall performance of
all 35 employees either met standards or were rated higher, there was no
evidence that the rater and the employee had formulated a written plan to
help in the growth of the employee, as required by MDOT policy.
In addition, for 34 employees (49 percent) tested, MDOT had not ensured that
criteria assessment sheets were completed and included in the appraisal
documentation for the period ended December 31, 2015. For example, the
criteria assessment sheet is used to assess performance for 27 attributes
comprising seven of the eight rating categories (for example, job knowledge,
job quality) on the evaluation form. Consequently, assurance was lacking that
all attributes were appropriately considered for the rating, which could affect
the integrity of evaluation results.
41

--- Page 44 ---
Similar results regarding the lack of a development plan and/or criteria
assessment sheets were noted for the appraisals of 32 of the 64 MDOT
employees tested for the period ended December 31, 2014.
Recommendation 7
We recommend that
a. the five agencies develop procedures to monitor the content of end-of-
cycle or annual performance evaluations given to employees for
compliance with legal requirements or policy,
b. the four agencies in SPMS ensure that measurable and objective
performance standards have been established for each position
description, and
c. MDOT ensure that development plans and criteria assessment sheets are
prepared for each evaluation and support the evaluation rating.
Finding 8
None of the five agencies reviewed had established a documented process to
sufficiently track and monitor each of their supervisors to ensure they had
received performance appraisal training.
Analysis
None of the five agencies reviewed had established a documented process to
sufficiently track and monitor each of their supervisors to ensure they had
received performance appraisal training. Specifically, we were advised by
human resources management employees from three of the four agencies in
the SPMS that no procedure had been established to ensure that all agency
supervisors received required performance appraisal training from OPSB,
from an in-house training program, or online through DBM’s Learning
Management System. State Personnel and Pensions Article Title 7, Subtitle 5,
of the Annotated Code of Maryland requires that each employee receive
training in the methods and procedures required in the performance appraisal
process. We were advised by the remaining agency (DHS) that it had
established a process to track supervisor training, but at the time of our
review, was unable to provide documentation that the training status of all
supervisors was adequately monitored, as there was no evidence to support
the training status of all supervisors (who either received or did not receive
training).
We were advised by MDOT that each administration is responsible for training
its supervisors on preparing and giving performance evaluations and such
training is strongly recommended but not mandatory. In this regard, we were
unable to locate any instruction from MDOT regarding the training
42

--- Page 45 ---
expectations for supervisors. Although most of the five MDOT business units
had established such training programs, we were advised that training
provided was not tracked by recipient.
As identified in Finding 7, many performance evaluations we reviewed were
not complete as they lacked the required content. This condition may indicate
that supervisors need to be better trained in the correct preparation of
performance appraisals. The use of tracking systems would help ensure that
such training was provided.
Recommendation 8
We recommend that
a. the agencies cited above establish a documented process to track and
monitor whether each of their supervisors has received performance
appraisal training and to ensure training requirements are met; and
b. MDOT formalize its training expectations and, in doing so, consider
mandating such training for each supervisor.
43

--- Page 46 ---
Exhibit 1
page 1 of 2
DBM Annual Personnel Report
Distribution of Employee Performance by Category by Principal Department
As of June 30, 2016
Total
Number of Number of Number of Number of Total
Employees 1 Employees Employees Employees Number of Percent of
To be Rated Rated Rated Employees Employees
Department Rated 2 Outstanding Satisfactory Unsatisfactory Rated Rated5
1 Aging 3 30 14 13 2 29 96.7%
2 Agriculture 325 157 147 3 307 94.5%
Budget and
3 Management 280 81 192 - 273 97.5%
4 Commerce 187 76 83 - 159 85.0%
5 Disabilities 24 8 10 - 18 75.0%
6 Education 1,277 631 476 7 1,114 87.2%
7 Environment 809 341 425 1 767 94.8%
General
8 Services 525 115 320 1 436 83.0%
9 Health 7,967 2,551 4,145 28 6,724 84.4%
Housing and
Community
10 Development 293 72 172 5 249 85.0%
11 Human Services 5,788 1,215 4,512 34 5,761 99.5%
Information
12 Technology 142 37 103 - 140 98.6%
Juvenile
13 Services 1,775 484 1,244 8 1,736 97.8%
Labor,
Licensing, and
14 Regulation 1,330 489 685 5 1,179 88.6%
Natural
15 Resources 4 1,214 516 432 1 1,172 96.5%
Notes
1 Actual Employees not FTEs
2 Does not include some contractual, permanent, and Executive Pay Plan employees who are rated using a
different evaluation instrument.
3 This data does not include the Senior Citizen Aides employees.
4 Total Number of Employees Rated includes employees rated with alternate evaluations systems.
5 Percentages were not included in DBM report and were calculated by OLA.
Source: OPSB Annual Personnel Report for period ending June 30, 2016
44

--- Page 47 ---
Exhibit 1
page 2 of 2
DBM Annual Personnel Report
Distribution of Employee Performance by Category by Principal Department
As of June 30, 2016
Total
Number of Number of Number of Number of Total
Employees 1 Employees Employees Employees Number of Percent of
To be Rated Rated Rated Employees Employees
Department Rated 2 Outstanding Satisfactory Unsatisfactory Rated Rated5
16 Planning 119 73 38 - 111 93.3%
Public Safety
and Correctional
17 Services* 9,566 1,642 3,841 35 6,569 68.7%
18 State Police 4 2,193 422 246 - 2,056 93.8%
19 Transportation 4 5,868 - - - 5,091 86.8%
20 Veterans Affairs 72 29 29 1 59 81.9%
All Other
21 Agencies 5,487 1,514 2,520 15 4,049 73.8%
Totals 45,271 10,467 19,633 146 37,999 83.9%
Notes
1 Actual Employees not FTEs
2 Does not include some contractual, permanent, and Executive Pay Plan employees who are rated using a
different evaluation instrument.
3 This data does not include the Senior Citizen Aides employees (refer to page 44).
4 Total Number of Employees Rated includes employees rated with alternate evaluations systems.
5 Percentages were not included in DBM report and were calculated by OLA.
*Additional PEP ratings submitted without rating category breakdown.
Source: OPSB Annual Personnel Report for period ending June 30, 2016
45

--- Page 48 ---
Exhibit 2
page 1 of 3
Breakdown of “All Other Agencies” Requested by OLA
As of June 30, 2016
Total
Number of Number of Number of Number of Total
Employees 1 Employees Employees Employees Number of Percent of
Department or To be Rated Rated Rated Employees Employees
Agency Rated 2 Outstanding Satisfactory Unsatisfactory Rated Rated3
Administrative
1 Hearings 111 40 22 - 62 55.9%
2 Archives 61 38 22 - 60 98.4%
Assessments and
3 Taxation 527 62 358 1 421 79.9%
4 Attorney General 623 229 192 1 422 67.7%
Automobile
5 Insurance Fund - - - - - 0.0%
Board of Public
6 Works 8 - - - - 0.0%
Boards,
Commissions
7 and Offices 85 48 10 - 58 68.2%
8 Civil Rights 25 9 15 - 24 96.0%
College Savings
Plans of
9 Maryland 13 2 8 1 11 84.6%
10 Comptroller 1,000 195 559 2 756 75.6%
11 Contract Appeals 2 2 - - 2 100.0%
Deaf and Hard of
12 Hearing 1 - - - - 0.0%
13 Elections 189 61 78 1 140 74.1%
Emergency
Management
14 Agency 52 2 39 - 41 78.8%
Emergency
Medical Services
15 Systems 82 35 38 1 74 90.2%
Energy
16 Administration 17 2 - - 2 11.8%
Notes
1 Actual Employees not FTEs
2 Does not include some contractual, permanent, and Executive Pay Plan employees who are rated using a
different evaluation instrument.
3 Percentages were not included in DBM report and were calculated by OLA.
Source: OPSB
46

--- Page 49 ---
Exhibit 2
page 2 of 3
Breakdown of “All Other Agencies” Requested by OLA
As of June 30, 2016
Total
Number of Number of Number of Number of Total
Employees 1 Employees Employees Employees Number of Percent of
Department or To be Rated Rated Rated Employees Employees
Agency Rated 2 Outstanding Satisfactory Unsatisfactory Rated Rated3
Executive
17 Department 78 6 4 - 10 12.8%
Governor’s Office
18 for Children 14 - 4 1 5 35.7%
Health Insurance
19 Plan - - - - - 0.0%
Higher Education
20 Commission 42 - 19 1 20 47.6%
Insurance
21 Administration 227 80 138 - 218 96.0%
Interagency
Committee on
School
22 Construction 17 10 3 - 13 76.5%
Lottery and
Gaming Control
23 Agency 293 88 154 1 243 82.9%
Military
24 Department 216 101 90 - 191 88.4%
25 People’s Counsel 9 6 3 - 9 100.0%
Property Tax
Assessment
26 Appeals Boards 6 5 1 - 6 100.0%
27 Public Defender 847 318 205 - 523 61.7%
Public Service
28 Commission 123 41 28 1 70 56.9%
Public
Broadcasting
29 Commission 134 10 114 - 124 92.5%
School for the
30 Deaf 321 14 218 4 236 73.5%
Secretary of
31 State 23 - - - - 0.0%
Notes
1 Actual Employees not FTEs
2 Does not include some contractual, permanent, and Executive Pay Plan employees who are rated using a
different evaluation instrument.
3 Percentages were not included in DBM report and were calculated by OLA.
Source: OPSB
47

--- Page 50 ---
Exhibit 2
page 3 of 3
Breakdown of “All Other Agencies” Requested by OLA
As of June 30, 2016
Total
Number of Number of Number of Number of Total
Employees 1 Employees Employees Employees Number of Percent of
Department or To be Rated Rated Rated Employees Employees
Agency Rated 2 Outstanding Satisfactory Unsatisfactory Rated Rated3
Stadium
32 Authority 74 - - - - 0.0%
33 State Prosecutor 10 9 1 - 10 100.0%
State Retirement
34 Agency 165 54 92 - 146 88.5%
Subsequent
35 Injury Fund 9 4 5 - 9 100.0%
Supplemental
36 Retirement Plans 12 6 6 - 12 100.0%
37 Tax Court 2 2 - - 2 100.0%
38 Treasurer 42 17 21 - 38 90.5%
Uninsured
39 Employers’ Fund - - - - - 0.0%
Workers’
Compensation
40 Commission 101 18 73 - 91 90.1%
Totals 5,561* 1,514 2,520 15 4,049 72.6%
Notes
1 Actual Employees not FTEs
2 Does not include some contractual, permanent, and Executive Pay Plan employees who are rated using a
different evaluation instrument.
3 Percentages were not included in DBM report and were calculated by OLA.
*Total employees to be rated includes 74 additional employees not included in APR from agencies with
independent personnel systems (such as Stadium Authority).
Source: OPSB
48

--- Page 51 ---
Exhibit 3
State of Maryland Performance Evaluation
For Non-Supervisory Employees
page 1 of 4
This evaluation is intended to facilitate communication between supervisors and employees regarding
expectations of job performance and to provide a mechanism for the evaluation of actual performance.
Employee Name: Beginning Date:January
Supervisor's Name: Fiscal Year:
Employee Status: Special Appointment Management Service
Executive Service Political Special Appointment
Does the employee's Position Description (PD) accurately reflect the current, and anticipated, duties and
responsibilities for the upcoming review period? (If no, modify the PD as required before beginning the
review period.)
Yes No - Date Modified:
Ratings:
3 = Outstanding: Exceptional performance. Achievements are clearly superior
to the level of performance required for the job.
2 = Satisfactory Met the required and expected results for the job. Good
performance which is expected of a fully experienced
or competent employee.
1 = Unsatisfactory: Performance is unacceptable and shows no significant
progress or improvement. Improvement is critical.
Performance of Job Duties (rate individual Position-Specific Performance Mid End
Standards only if Overall Work Quality is Unsatisfactory) Cycle Cycle
Rating Rating
1 Overall Work Quality
2
3
4
5
6
7
Number of Position-Specific Performance Elements Rated: 0 0
49

--- Page 52 ---
Exhibit 3
State of Maryland Performance Evaluation
For Non-Supervisory Employees
page 2 of 4
Mid End
Cycle Cycle
Behavioral Elements Rating Rating
Work Ethic
1 Maintains good attendance (The use of FMLA-qualifing leave should not be
considered)
2 Follows call-in/leave policies
3 Reports to work area on time and does not leave until designated time
Team-Work
4 Works cooperatively with others to implement the Department's goals
Communication
5 Speaks effectively
6 Writes effectively (clear, organized, appropriate grammar,
punctuation)
7 Interacts positively with co-workers
Customer Service
8 Strives to meet customer requirements
9 Is courteous to customers and co-workers
10 Provides timely, accurate and appropriate information to internal
and external customers
11 Presents a professional image to customers in attire and maintenance of
workspace
12 Keeps commitments and follows through on customer requests
Initiatives
13 Solves problems without being asked
14 Works to continuously improve processes
15 Engages in opportunities for self-improvement
Work Performance
16 Appropriately prioritizes work
17 Completes assignments accurately and on time
18 Maintains confidentiality
19 Exercises appropriate judgment
20 Follows directions
Number of Behavioral Elements Rated: 0 0
Total Number of Elements Rated: 0 0
50

--- Page 53 ---
Exhibit 3
State of Maryland Performance Evaluation
For Non-Supervisory Employees
page 3 of 4
Mid Cycle Rating:
Outstanding Satisfactory Unsatisfactory
3.00 - 2.75 2.74 - 1.75 1.74 - 1.00
Tasks to be Achieved Before the End of Cycle Rating:
Training Recommendations:
Supervisor's Comments:
Employee's Comments:
I understand that this is a: Special Appointment; Management Service; ___Executive Service;
___Political Special Appointment position in which I serve at the pleasure of the appointing authority.
Employee Signature: Date:
No personnel action shall be taken or refused as a reprisal against an employee
who refuses to sign this evaluation. The supervisor shall note the refusal on the
employee's signature line.
Supervisor Signature: Date:
By my signature I attest that I understand and adhere to the Governor's Code of Fair Employment
Practices, 01.01.2007.16.
Division Manager: Date:
51

--- Page 54 ---
Exhibit 3
State of Maryland Performance Evaluation
For Non-Supervisory Employees
page 4 of 4
End Cycle Rating:
Outstanding Satisfactory Unsatisfactory
3.00 - 2.75 2.74 - 1.75 1.74 - 1.00
Tasks to be Achieved Before the Next Mid-Cycle Rating:
Training Recommendations:
Supervisor's Comments:
Employee's Comments:
I understand that this is a: Special Appointment; Management Service; ___Executive Service;
___Political Special Appointment position in which I serve at the pleasure of the appointing authority.
Employee Signature: Date:
No personnel action shall be taken or refused as a reprisal against an employee
who refuses to sign this evaluation. The supervisor shall note the refusal on the
employee's signature line.
Supervisor Signature Date:
By my signature I attest that I understand and adhere to the Governor's Code of Fair Employment
Practices, 01.01.2007.16.
Appointing Authority: Date:
(Revised 5/20/10)
Source: DBM website
52

--- Page 55 ---
Exhibit 4
Employee Performance Evaluation Survey Results
page 1 of 4
In August 2017, we conducted an online survey of 95 employees of the 131
employees from our Statewide statistical test (refer to footnote 2 on page 15).
Responses were received from 53 employees. Below are the survey
questions and summary of responses.
1. Did you receive a written performance evaluation from
your supervisor during the past year?
96.2%
Yes
No 3.8%
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
Answer Choices Number of Responses Percent of Responses
Yes 51 96.2%
No 2 3.8%
Total 53 100.0%
2. If you received a written performance evaluation, what
was the “End Cycle Rating”?
Outstanding 45.1%
Satisfactory 54.9%
Unsatisfactory 0.0%
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
Answer Choices Number of Responses Percent of Responses
Outstanding 23 45.1%
Satisfactory 28 54.9%
Unsatisfactory 0 0.0%
Total 51 100.0%
Skipped Question 2 -
53

--- Page 56 ---
Exhibit 4
Employee Performance Evaluation Survey Results
page 2 of 4
3. Do you believe that the written evaluation fairly assessed
your performance during the rating period?
Yes 81.1%
No, I believe my
0.0%
rating was too high
No, I believe my
18.9%
rating was too low
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
Answer Choices Number of Responses Percent of Responses
Yes 43 81.1%
No, I believe my rating
was too high 0 0.0%
No, I believe my rating
was too low 10 18.9%
Total 53 100.0%
4. For your last evaluation cycle, were ‘Tasks to be Achieved
before the Next Cycle Rating’ identified?
Yes, in writing 50.0%
Yes, verbally 17.3%
No 13.5%
Not applicable,
no performance 19.2%
improvement needed
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
54

--- Page 57 ---
Exhibit 4
Employee Performance Evaluation Survey Results
page 3 of 4
Answer Choices Number of Responses Percent of Responses
Yes, in writing 26 50.0%
Yes, verbally 9 17.3%
No 7 13.5%
Not applicable,
no performance
improvement needed 10 19.2%
Total 52 100.0%
Skipped question 1 -
5. For your last evaluation cycle, were you provided “Training
Recommendations” or instructed on how you could improve
where needed?
Yes, in writing 30.2%
Yes, verbally 9.4%
No 24.5%
Not applicable,
35.9%
no training needed
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
Answer Choices Number of Responses Percent of Responses
Yes, in writing 16 30.2%
Yes, verbally 5 9.4%
No 13 24.5%
Not applicable,
no training needed 19 35.9%
Total 53 100.0%
55

--- Page 58 ---
Exhibit 4
Employee Performance Evaluation Survey Results
page 4 of 4
6. The stated purpose of the performance evaluation
program is to facilitate communication between employees
and supervisors regarding expectations and job
performance. Do you believe that the program successfully
accomplishes that purpose?
Yes 62.2%
No 20.8%
No opinion 17.0%
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
Answer Choices Number of Responses Percent of Responses
Yes 33 62.2%
No 11 20.8%
No opinion 9 17.0%
Total 53 100.0%
56

--- Page 59 ---
Exhibit 5
Supervisor Performance Evaluation Survey Results
page 1 of 5
In August 2017, we conducted an online survey of 106 supervisors of the 131
employees from our Statewide statistical test (refer to footnote 2 on page 15).
Responses were received from 66 supervisors. Below are the survey
questions and summary of responses.
1. Indicate all sources of training you received in the past on
how to conduct employee evaluations. Check all that apply
In-person training from DBM-OPSB 22.7%
Online training from SPS (The HUB) 57.6%
In-house training from my agency 62.1%
I have not received any training 6.1%
0% 20% 40% 60% 80% 100%
Answer Choices Number of Percent of
Responses Responses
In-person training from DBM-Office of
Personnel Services and Benefits (OPSB) 15 22.7%
Online training from the SPS training module
(The HUB) 38 57.6%
In-house training from my agency 41 62.1%
I have not received any training 4 6.1%
Total 66 -
57

--- Page 60 ---
Exhibit 5
Supervisor Performance Evaluation Survey Results
page 2 of 5
2. If you received training, was it a useful tool to aid you in
conducting evaluations with the employee(s) you supervise?
Yes 82.0%
No 18.0%
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
Answer Choices Number of Responses Percent of Responses
Yes 50 82.0%
No 11 18.0%
Total 61 100.0%
Skipped question 5 -
3. Please indicate the number of employees you directly
supervise.
1 to 5 employees 38.5%
6 to 10 employees 36.9%
11 to 20 employees 16.9%
21 to 50 employees 4.6%
Over 50 employees 3.1%
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
58

--- Page 61 ---
Exhibit 5
page 3 of 5
Supervisor Performance Evaluation Survey Results
Answer Choices Number of Responses Percent of Responses
1 to 5 employees 25 38.5%
6 to 10 employees 24 36.9%
11 to 20 employees 11 16.9%
21 to 50 employees 3 4.6%
Over 50 employees 2 3.1%
Total 65 100.0%
Skipped question 1 -
4. Please indicate the extent to which you completed written
evaluations for the employees you directly supervised during
the last rating cycle.
All employees were evaluated 86.4%
Not all, but at least half of
9.1%
employees were evaluated
Fewer than half of employees
3.0%
were evaluated
None of the employees
1.5%
were evaluated
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
Answer Choices Number of Percent of
Responses Responses
All employees were evaluated 57 86.4%
Not all, but at least half of employees were
evaluated 6 9.1%
Fewer than half of employees were evaluated 2 3.0%
None of the employees were evaluated 1 1.5%
Total 66 100.0%
59

--- Page 62 ---
Exhibit 5
Supervisor Performance Evaluation Survey Results
page 4 of 5
5. The stated purpose of the performance evaluation
program is to facilitate communication between employees
and supervisors regarding expectations and job
performance. Do you believe that the program successfully
accomplishes that purpose?
Yes 53.8%
No 27.7%
No opinion 18.5%
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
Answer Choices Number of Responses Percent of Responses
Yes 35 53.8%
No 18 27.7%
No opinion 12 18.5%
Total 65 100.0%
Skipped question 1 -
60

--- Page 63 ---
Exhibit 5
Supervisor Performance Evaluation Survey Results
page 5 of 5
6. To help us make better use of the results of this
anonymous survey, please indicate the type of position you
occupy at your agency.
Upper Management 19.7%
Management 30.3%
Supervisor 48.5%
Prefer not to disclose 1.5%
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
Answer Choices Number of Percent of
Responses Responses
Upper Management (such as agency heads,
directors, administrators, and their deputies) 13 19.7%
Management (office, division or unit managers,
assistant managers, and chiefs) 20 30.3%
Supervisor (various positions that supervise
frontline workers) 32 48.5%
Other (please indicate below) 0 0.0%
Prefer not to disclose 1 1.5%
Total 66 100.0%
61

--- Page 65 ---
Department of Budget and Management
Office of Personnel Services and Benefits (OPSB)
Response to Legislative Audits Findings and Recommendations
Performance Audit on the State Employee Performance Evaluation Program
Finding 1
Many employees had not received required evaluations during a five-year period and OPSB
had not established a comprehensive strategy to improve agency compliance or ensure
agencies monitored their efforts.
Recommendation 1
We recommend that OPSB
a. develop comprehensive strategies for addressing agency non-compliance with employee
performance evaluation requirements;
b. amend existing PEP Guidelines to specify that all applicable Executive Branch agencies use
SPS to record evaluations and track evaluation activity, as well as to institute appropriate
internal follow-up to improve evaluation completion performance; and
c. monitor SPS evaluation data to identify trends to target follow-up efforts.
DBM OPSB Response 1:
a. We agree that a comprehensive strategy is necessary to improve PEP completion rates. We
have updated our schedule for sending reminders to agency HR Directors and Secretaries.
Within 15 days prior to the due dates, we will examine completion rates and including that
information with reminders to agencies. Agencies having a completion rate below 92% one
month after the PEP due date will receive a letter from the DBM Secretary to the agency head
requesting a detailed response including an action plan for completing the outstanding PEPs.
Additionally, we have contacted DHS and plan to review their internal evaluation tracking
procedures to assess their utility across all SPMS agencies. We will adopt or revise these
procedures, as appropriate, and disseminate these best practices to all SPMS agencies, along
with an announced strategy for dealing with non-compliance, with a specific emphasis on
chronic non-compliant agencies.
b. Typically, we would not use instructional guidance, such as the OPSB PEP Guidelines as the
communication tool for notifying agencies to record their PEP results in the SPS. This type of
instruction usually occurs in meetings that OPSB has with SPMS agencies and through field
memos sent periodically to all agencies on a variety of topics; however, we will update the PEP
Guidelines to include a reminder to SPMS agencies of their obligation to record PEP
evaluations in the SPS as soon as possible. We also will include instructions for pulling PEP
reports from the SPS that agencies should be using to track their progress on completing PEPs.
We note that agencies that fail to record PEP scores in the SPS within 4 months of the due date
do not have the ability to enter these scores due to system limitations.

--- Page 66 ---
c. Through efforts noted above in the response to recommendation a, we will be monitoring the
SPS evaluation data and will focus follow-up efforts in areas where needed.
Finding 2
OPSB did not disclose certain information in the APR needed to better interpret and clarify
the performance evaluation results. In addition, complete records supporting the APR were
not maintained and controls were not established to ensure the accuracy of SPS data used to
compile the APR.
Recommendation 2
We recommend that OPSB
a. disclose the methodology used to prepare the APR and consider reporting evaluation data for an
entire fiscal year;
b. obtain and report employee performance evaluation results for all Executive Branch agencies in
the APR as required by law;
c. expand the number of agencies individually listed on the APR (for example, individually list
principal agencies and other agencies with greater than 50 employees);
d. develop an automated capability to compile evaluation data for the preparation of the APR to
eliminate the need for manual records, otherwise establish appropriate manual controls and
recordkeeping to support APR data;
e. establish procedures to verify that agencies accurately recorded evaluations in SPS; and
f. require agencies to establish controls to ensure all evaluations given were properly and
accurately recorded in SPS
DBM OPSB Response 2:
a. OPSB will update the language on the Annual Personnel Report to provide additional information
on the methodology used to compile the data. In addition, OPSB will consider reporting
evaluation data for an entire fiscal year and not for the six-month period ending on June 30.
We will explore additional reporting capabilities in the SPS to determine if it is possible to
develop an automated custom PEP report to capture more details at specific times and will
document the controls we have in place for capturing the data.
b. Per advice from legal counsel, all independent Executive Branch agencies will be required to
provide the specific data on their employee performance evaluations. Beginning with the 2018
APR, results for all Executive Branch agencies will be included as required by law. The
independent agencies must report this information to OPSB since it is not included in the SPS
and cannot be entered into the SPS.
c. DBM individually has reported PEP completion rates for each agency within the SPMS beginning
with the Fiscal Year 2017 Annual Report, and intends to continue to do so.

--- Page 67 ---
d. OPSB currently is in the process of obtaining custom reports to compile evaluation for the APR;
we estimate that these reports will be available in FY 2019.
e. Each agency HR office is responsible for ensuring the accuracy of the data entered into the SPS.
OPSB has training available on the HUB and can provide each agency with best practices for
managing the PEP process for their agency. We will require the Agency HR offices to perform
independent reviews of a random sampling of PEPs to ensure accurate recordation. To ensure
agencies are complying with this requirement, we will periodically review documentation of a
sample of these agency self-reviews conducted. We also intend to develop a certification and
require each agency Personnel Director to sign off to certify that, to the best of their knowledge
and belief, the information submitted is accurate.
f. Effective no later than June 1, 2018, we will institute a requirement that agencies have to perform
a random sampling of their PEP evaluations to ensure that the rating instruments exist and are
recorded accurately in the SPS. As mentioned in response to recommendation 2e and to ensure
agencies are complying with this requirement, we will periodically review documentation of a
sample of these agency self-reviews conducted. OPSB will explore establishing data input
controls.
Finding 3
OPSB had not established a process to ensure performance evaluations were based on
measurable standards and their content met legal requirements.
Recommendation 3
We recommend that OPSB
a. establish procedures for reviewing completed evaluations and position descriptions, at least on a
test basis, for sufficiency of content;
b. ensure the applicable agencies are notified of deficiencies and take appropriate corrective
actions;
c. enhance and clarify the PEP Guidelines to require the establishment of measurable performance
standards in position descriptions and to require that end-of-cycle evaluations include written
specific tasks to be achieved by employees during the next rating period as required by State law;
and
d. ensure consistency in its PEP Guidelines and MS-22 instructions.
DBM OPSB Response 3:
a. OPSB will issue best practices to agencies regarding the development of performance
standards and the completion of the PEP forms. We also intend to develop a checklist for
supervisors and agency HR offices to use when completing and reviewing their PEPs. As
part of the review of a random sample (mentioned in response to Recommendation 2e),
completed evaluations will be reviewed for related position descriptions to ensure they
included measurable standards. As mentioned in response to recommendation 2e and to
ensure agencies are complying with this requirement, we will periodically review
documentation of a sample of these agency self-reviews conducted.

--- Page 68 ---
b. OPSB will remind agencies of the requirement to include observable, measurable, and objective
performance standards for each essential job function listed on the MS-22 in accordance with the
PEP Guidelines. We will review and update the PEP Guidelines against the instructions for
completing the MS-22 and resolve the discrepancies that were noted in the Analysis.
c. Based on the analysis, it appears that the DLS is of the opinion that “specific tasks” to be
achieved are required on each employee’s end-cycle PEP. The Department respectfully
disagrees. “Specific tasks” to be achieved by employees are of a non-routine nature, outside of
the employee’s day-to-day responsibilities; an example of this would be a special project
assigned to an employee. Not all employees will have specific tasks of a non-routine nature
assigned to them during a rating period, but when such tasks are assigned, it is appropriate to
note this requirement on an employee’s PEP.
Advice from our AAG indicated that, per the law, specific written “tasks” should be included in
the specified area on the PEP forms but only when related to the employee’s performance of the
overall objectives of the position. Thus, not all employees will have identified tasks to list on the
PEP form. The AAG indicated that it was reasonable to require supervisors to state “None”
when there are no identified specific tasks. Additionally, the AAG also agreed that the
supervisor comments and training recommendations areas were the most appropriate place to
include areas or actions that might be taken in which an employee could improve performance.
We will review and update the PEP Guidelines as appropriate to provide additional guidance as
to when “specific tasks” should be included. When there are no specific tasks, supervisors will
be instructed to indicate this (i.e., write in “none” for tasks to be achieved before next rating).
The PEP Guidelines will also be updated to note that supervisors should include comments on
what an employee can do to improve his or her rating under training recommendations and
supervisor’s comments.
d. As PEP Guidelines are updated, OPBS will ensure consistency in its PEP Guidelines and MS-22
instructions
Finding 4
OPSB did not clearly set the expectations for required mandatory PEP-related training for
supervisory and managerial employees, require the maintenance of agency-based training
records, or monitor agency training efforts.
Recommendation 4
We recommend that OPSB ensure compliance with State law requiring it to provide PEP training to
agency supervisors. Specifically, OPSB should
a. clearly communicate its training expectations to state agencies, including the need to ensure all
supervisors and managers are properly trained;
b. require state agencies to maintain detail PEP records to track PEP training provided to each
supervisor and manager to substantiate the requirements of State law have been met; and
c. monitor state agency PEP training efforts, including employee attendance/participation by
requiring periodic reports on training activities.

--- Page 69 ---
DBM OPSB Response 4:
a. The analysis indicate that OPSB did not communicate its expectation that agency employees
who attended OPSB’s in-person PEP training courses would be responsible for training all
supervisory personnel at their agencies. We respectfully disagree that we did not communicate
this expectation since the subject of the training indicated that it was “train-the-trainer” PEP
training; however, we do agree that for a variety of reasons known only to the individual
agencies, in many cases the training was not delivered.
Since 2014, we have offered on-line PEP training directly to all SPMS supervisors and managers
via The Hub, the State’s online learning management system. This training includes a “learning
check” component, which gives the learner an opportunity to gauge how well (s)he is grasping
the material.
OPSB will send out periodic reminders to all agencies that training is mandatory for supervisors
and managers who are responsible for preparing performance evaluations.
b. For those agencies performing in-person PEP training, we will issue reminders of the importance
of tracking completion of the training. Agencies that provide in-house training will be required
to maintain records of those that received the training. We have the ability to pull reports on
training completion for those supervisors/managers who are taking PEP training online via The
Hub.
c. We will ask agencies to provide periodic reports on their training activities.
Finding 5
OPSB had not developed approaches to formally evaluate the effectiveness of the PEP as well
as training courses for managers and supervisors.
Recommendation 5
We recommend that OPSB
a. develop approaches, such as employee surveys, for evaluating the effectiveness of the PEP and
the OPSB training; and
b. reassess the appropriateness of PEP Guidelines pertaining to evaluating employee work quality
for those rated satisfactory or better.
DBM OPSB Response 5:
a. The fact that some employees (ranging between 21 to 28%) believe that the PEP is not an
effective tool for evaluating performance is not, in and of itself, evidence of ineffectiveness;
however, we agree that enhancements to our guidance and training materials would be useful and
we agree to make those adjustments. OPSB will explore approaches, such as employee surveys,
to determine the best method to evaluate the effectiveness of the PEP and the OPSB training.

--- Page 70 ---
b. OLA suggests that OPSB should reconsider the guidance on rating employee work quality,
which OLA believes compromises the effectiveness of the PEP process; specifically, the
guidance that a supervisor need not formally rate employee performance for each essential job
function if the overall work quality is rated satisfactory or better. In other words, a supervisor
may give an overall rating of Satisfactory or Outstanding for all of the rated essential job
functions, and is required to individually rate these elements only if an element is unsatisfactory.
OPSB understands the concern that OLA is raising; however, this suggestion came out of
discussions with members of the General Assembly, and put forth as a way to try to streamline
the process and increase PEP completion rates. This suggestion was taken up by the PEP Task
Force (a joint labor/management effort) and was adopted as a practice. In addition, this
‘streamlined’ process developed from collective bargaining discussions. Any changes to this
process would have to be brought up and discussed (and agreed upon) through additional
collective bargaining discussions.

--- Page 71 ---
Department of Public Safety and Correctional Services
Office of the Secretary • Human Resources Services Division
6776 REISTERSTOWN ROAD • SUITE 309 • BALTIMORE, MARYLAND 21215-2341
STATE OF MARYLAND (410) 585-3408 • FAX (410) 764-4348 • V/TTY (800) 735-2258 • www.dpscs.state.md.us
LARRY HOGAN
GOVERNOR
BOYD K. RUTHERFORD
LT. GOVERNOR June 4, 2018
STEPHEN T. MOYER
SECRETARY
WILLIAM G. STEWART
DEPUTY SECRETARY
J. MICHAEL ZEIGLER
DEPUTY SECRETARY Mr. Thomas J. Barnickel III, CPA
GREGORY A. MARSHALL Department of Legislative Services
EXECUTIVE DIRECTOR
Office of Legislative Audits
SANDRA E. REGLER
DEPUTY DIRECTOR 301 West Preston Street, Room 1202
TARA NELSON
Baltimore, Maryland 21201
DEPUTY DIRECTOR
Dear Mr. Barnickel:
The Department of Public Safety and Correctional Services (DPSCS) has reviewed the
Draft Audit Report dated May 2018 for the Department of Budget and Management’s
Oversight of the State Employee Performance Evaluation Program (PEP). The
Department appreciates the constructive findings and recommendations that were
made as the result of this audit.
Please find attached the Department’s itemized responses to the Draft Audit Report as
submitted by Gregory A. Marshall, Executive Director of the Human Resources
Services Division. Mr. Marshall and his management team have begun, and will
continue to implement the necessary corrective action to address the audit findings and
recommendations, and will closely monitor their status in order to prevent any repeat
audit findings in the next audit.
The Office of the Inspector General will also conduct periodic follow up reviews to
monitor the status of compliance.
If you have any questions regarding the Department’s response, please contact me.
Sincerely,
Stephen T. Moyer
Secretary
Cc: Walter Landon, Deputy Chief of Staff

--- Page 73 ---
We agree.
a. and b.
Mr. Gregory A. Marshall became the Executive Director of the Human Resources
Services Division (HRSD) in the Spring of 2017. Upon being appointed, Mr. Marshall
directed a review of the PEP process, which falls under HRSD. As a result of this
review, Mr. Marshall has implemented or will implement the following process
enhancements:
1. DPSCS established procedures for routine monitoring of personnel system data
that ensures employee performance evaluations are completed as required by
statute or regulation. These procedures are carried out by the HRSD, Human
Resources Information Unit.
2. During each PEP cycle, a Department-wide announcement is distributed to all
managers responsible for PEP completion. The announcement provides due
dates for completions and advises that the Department of Budget and
Management (DBM) requires all PEP data be entered into Workday (personnel
record system) by a certain date. HRSD is responsible for entering the PEP
data.
3. During the PEP cycle, HRSD monitors the progress. Updates are provided to
Appointing Authorities that detail their completion rate. Status spreadsheets
are attached to email messages, which identify institutions, and Departmental
agencies/units that have outstanding PEPs due.
4. Appointing Authorities are being instructed to forward all finalized PEPs to the
appropriate Human Resources regional office supporting their organizations,
where they are accurately recorded into Workday. By 7/15/18, HRSD will
begin performing spot check verifications to ensure that the PEP data is
properly recorded in the Workday personnel system. The spot checks will be
conducted by a designated HRSD Supervisor and based on a random sampling
methodology. Additionally, the spot checks will be documented (including
who did the reviews, dates of reviews, and findings) and retained for future
audit purposes.
It should be noted that DBM monitors DPSCS progress and reports out completion
rates to the Secretary. To that end, in FY 17, the PEP completion percentage improved
to 92.49%, and through December 2017, the percentage completion increased to
93.46%.
HRSD Responses – PEP Audit Page 2 of 5

--- Page 74 ---
Finding 7
DPSCS had not effectively monitored the content of performance evaluations
given to employees for compliance with legal requirements or policy.
Recommendation 7
We recommend that DPSCS:
a. develop procedures to monitor the content of end-of-cycle or annual
performance evaluations given to employees for compliance with legal
requirements or policy; and,
b. ensure that position descriptions with measurable and objective performance
standards have been established for each position description.
We agree.
a. As identified in Finding 7, many performance evaluations reviewed were not
completed as they lacked the required content. This condition suggests that
supervisors need to be better trained in the correct preparation of performance
appraisals. The use of tracking systems would help ensure that such training was
provided.
The Appointing Authorities of the various Departmental agencies are the subject
matter-experts for their agencies. They are in the best positon to monitor the content of
end-of-cycle or annual performance evaluations for compliance with legal
requirements or policy. Effective immediately and ongoing, HRSD will work closely
with Appointing Authorities in this regard.
Effective immediately, DPSCS will also collaborate with DBM to provide ongoing
on-line PEP training to Appointing Authorities and other managers to ensure that
content within end-of-cycle or annual performance evaluations given to employees are
compliant with legal requirements or policy.
Further, HRSD will conduct “spot checks” to ensure that the content of end-of-cycle
or annual evaluations are in compliance with legal requirements or policy.
Specifically, by 7/15/18, the HRSD Operational Support Unit Supervisor within each
of the five (5) DPSCS regions will conduct random sampling spot checks (quality
control reviews) of PEPs from the correctional institutions they support. These spot
checks will be documented to capture the random sampling methodology used, the
HRSD Operational Support Unit Supervisor doing the reviews, the dates of the
reviews, and what his/her findings were. This documentation will be retained for
future audit purposes.
b. Appointing Authorities are in the best position to determine if job descriptions are
measurable and whether appropriate and objective performance standards have been
HRSD Responses – PEP Audit Page 3 of 5

--- Page 75 ---
established for each position description. For this reason, Appointing Authorities are
already required to review and approve each one of their employee’s Position
Descriptions (Form MS-22).
Effective immediately, DPSCS will collaborate with DBM to provide ongoing on-line
PEP training to Appointing Authorities and other managers to ensure that position
descriptions with measurable and objective performance standards have been
established for each position.
By 12/15/18, HRSD Supervisors will conduct spot checks to ensure that position
descriptions with measurable and objective performance standards have been
established for each position. The spot checks will be based on a random sampling
methodology, and will be documented, including who did the reviews, dates of
reviews, and findings. The documentation will be retained for future audit purposes.
Finding 8
DPSCS had not established a documented process to sufficiently track whether
each of their supervisors had received performance appraisal training.
Recommendation 8
We recommend that DPSCS establish procedures to track whether each of their
supervisors has received performance appraisal training and to ensure training
requirements are met.
We agree.
State Personnel and Pensions Article, Title 7, Subtitle 5 of the Annotated Code of
Maryland, requires DBM to provide mandatory training to each agency’s supervisors
on the methods and procedures required in the performance evaluation process.
Ms. Leslie Buchman, Director, Shared Services Division, Office of Personnel Services
and Benefits, Department of Budget and Management, 301 W. Preston St., Suite 507,
Baltimore, Maryland 21201, confirmed that DBM administers mandatory and ongoing
PEP computer-based training for supervisors and managers.
PEP, Performance, Planning and Evaluation, Module 1 is a DBM training module that
is made available for educational purposes and provides an overview of the concepts
relevant to the Performance Planning and Evaluation Program (PEP) within the State
Personnel Management System. DBM provides a report that tracks which agency
supervisors have or have not received performance appraisal training to ensure
training requirements are met.
HRSD Responses – PEP Audit Page 4 of 5

--- Page 78 ---
Maryland Department of Health
State Employee Performance Evaluation Program
Audit Responses
Findings and Recommendations
Finding 6
Certain agencies that were not using available personnel system records to
monitor completion of performance evaluations had many employees who
were not evaluated. None of the five agencies reviewed had established
controls over the recording of evaluation data in the personnel systems.
Recommendation 6
We recommend that
a. DPSCS, MDH, and MDOT establish procedures, such as routine
monitoring of personnel system data, to ensure employee performance
evaluations are completed as required by statute or regulation;
b. all five agencies establish processing controls to ensure all completed
evaluations had been accounted for and accurately recorded in the
applicable personnel system; and
c. MDOT maintain documentation to support evaluation data reported
annually to OPSB.
MDH’s Response
a. MDH concurs with the finding and recommendation. Beginning with the
July 2018 PEP cycle, MDH will begin using the “Next PEP Due” report
contained in SPS to track PEP completion by unit/division. MDH will contact
managers and/or HR liaisons in those units that are significantly deficient to
remind them of their responsibilities and offer training assistance, if needed.
MDH will continue this monitoring for future PEP cycles.
b. MDH concurs with the finding and recommendation. Beginning with the July
2018 PEP cycle, MDH will develop a process that will account for paper
evaluations received. MDH will also conduct a random sample of PEP entries
to ensure that the PEP score entered in SPS coincides with the score given for
the PEP cycle. The verification will not be conducted by the same person who
enters the scores.
c. This recommendation does not apply to MDH.

--- Page 79 ---
Finding 7
None of the five agencies reviewed had effectively monitored the content of
performance evaluations given to employees for compliance with legal
requirements or policy.
Recommendation 7
We recommend that
a. the five agencies develop procedures to monitor the content of end-of-
cycle or annual performance evaluations given to employees for
compliance with legal requirements or policy,
b. the four agencies in SPMS ensure that measurable and objective
performance standards have been established for each position
description, and
c. MDOT ensure that development plans and criteria assessment sheets are
prepared for each evaluation and support the evaluation rating.
MDH’s Response
a. MDH concurs with the finding and recommendation. In May 2018 MDH
communicated with its Human Resource Offices and Program Managers
regarding the sections of the PEP that must be completed. Beginning with the
January 1, 2019 PEP rating deadline, MDH will update training programs to
include the sections that must be completed. Also, beginning with the July
2018 PEP cycle MDH will review, on a sample basis, PEP for compliance
with legal requirements or policy.
b. MDH concurs with the recommendation. Beginning July 2018, MDH
Recruitment and Selection Unit will review each Employee’s Position
Description submitted when the hiring manager begins the process to post and
recruit for a vacant position. On average, MDH hires more than 800
employees per year. This represents approximately 10% of MDH’s overall
workforce.
c. This recommendation does not apply to MDH.

--- Page 80 ---
Finding 8
None of the five agencies reviewed had established a documented process to
sufficiently track and monitor each of their supervisors to ensure they had
received performance appraisal training.
Recommendation 8
We recommend that
a. the agencies cited above establish a documented process to track and
monitor whether each of their supervisors has received performance
appraisal training and to ensure training requirements are met; and
b. MDOT formalize its training expectations and, in doing so, consider
mandating such training for each supervisor.
MDH’s Response
a. MDH concurs with the finding and recommendation. In preparation for the
January 1, 2019 PEP due date, MDH will use training completion reports
contained in the SPS to identify those supervisors/managers who have not
completed the required PEP training. MDH will also identify an accessible
communication tool by which we can notify supervisors/managers or their
managers when training has not been completed.
b. This recommendation does not apply to MDH.

--- Page 82 ---
Appendix:
DHS Agency Response:
Finding 6
Certain agencies that were not using available personnel system records to monitor
completion of performance evaluations had many employees who were not evaluated.
None of the five agencies reviewed had established controls over the recording of
evaluation data in the personnel systems.
Recommendation 6
We recommend that
a. DPSCS, MDH, and MDOT establish procedures, such as routine monitoring of
personnel system data, to ensure employee performance evaluations are completed as
required by statute or regulation;
b. all five agencies establish processing controls to ensure all completed evaluations had
been accounted for and accurately recorded in the applicable personnel system; and
c. MDOT maintain documentation to support evaluation data reported annually to OPSB.
DHS response
Only subparagraph (b) of the recommendation applies to DHS.
DHS had controls in place to ensure all completed evaluations had been accounted for.
Specifically, DHS has been proactive in creating reports in the Workday system to assist in the
tracking of Performance Evaluation Program form (PEP) completions. Supervisors are provided
instructions for running various monitoring reports and entering the PEP score at least a week
prior to the start of each PEP period. The first report is run by supervisors to show PEPs due
(End or Mid-Cycle) for each member of their teams.
A second report is run by the Human Resources Development and Training unit to show any
PEP scores that have not been entered into the Workday system. This report is run on regular
intervals throughout the PEP completion period and supervisors who have not completed PEPs
are sent emails reminding them that the PEPs are due.
DHS agrees that better controls can be implemented to ensure that the PEP rating in the PEP
document is accurately transferred to the Workday system. Although the Department does not
have resources to cross check the data entry on all PEPs, we will provide staff with instructions
on how to review the PEP data entered into Workday and bring errors to the attention of HR for
correction. In addition, the Department will conduct an audit of at least 10% of End of Cycle
PEPs to identify any trends in data entry errors.

--- Page 83 ---
Finding 7
None of the five agencies reviewed had effectively monitored the content of performance
evaluations given to employees for compliance with legal requirements or policy.
Recommendation 7
We recommend that
a. the five agencies develop procedures to monitor the content of end-of-cycle or annual
performance evaluations given to employees for compliance with legal requirements or
policy,
b. the four agencies in SPMS ensure that measurable and objective performance
standards have been established for each position description, and
c. MDOT ensure that development plans and criteria assessment sheets are prepared for
each evaluation and support the evaluation rating.
DHS response
Only subparagraph (a) and (b) of the recommendation applies to DHS.
DHS concurs with the recommendations and began working to implement corrections prior to
this audit finding:
7(a) Consistent with the provisions of State Personnel and Pensions Article 7-503, DHS agrees
that it is the responsibility of the supervisor and appointing authority to ensure that PEPs comply
with all requirements. In fact, in the Fall of 2017, the Department rolled out a newly developed
PEP training which is being delivered to all DHS supervisory staff as mandatory training that
must be completed by June 30, 2018. This training emphasizes the requirements of the PEP,
including the need to include specific tasks to be achieved during the next rating period.
Although the Department does not have resources to review every PEP for quality assurance, the
Department will institute an audit of at least 10% of the End of Cycle PEPs completed each
cycle. This audit will be used to identify any trends in PEP deficiencies.
7(b) In addition, a newly developed mandatory MS-22 training was also rolled out in the Fall of
2017 for all supervisors/managers. The training provides guidance in the development of the
MS-22 to ensure realistic expectations and measurable performance standards are documented
for each position. In order to ensure quality, DHS will conduct an annual audit of 2% of MS-
22’s.
Finding 8
None of the five agencies reviewed had established a documented process to sufficiently
track and monitor each of their supervisors to ensure they had received performance
appraisal training.

--- Page 84 ---
Recommendation 8
We recommend that
a. the agencies cited above establish a documented process to track and monitor whether
each of their supervisors has received performance appraisal training and to ensure
training requirements are met; and
b. MDOT formalize its training expectations and, in doing so, consider mandating such
training for each supervisor.
DHS response
Only subparagraph (a) of the recommendation applies to DHS.
DHS has implemented a comprehensive training program for the Performance Planning and
Evaluation Program (PEP) and the MS-22. We currently have mandatory trainings underway for
all supervisors/managers. This training program began in the fall of 2017 and by June 30, 2018,
all existing DHS Supervisors will attend the training. After June 30, 2018, the program will
continue to ensure that new supervisors are properly trained.
The Department agrees that during the period assessed in the audit, there was no system in place
to track PEP training compliance for supervisors. However, prior to the audit finding, DHS took
steps to ensure that all Departmental training, including PEP and MS-22 training is scheduled
and tracked through the State’s Learning Management System (LMS). The Department has
created custom reports in LMS to track training completion. We provided copies of the training
completion reports to the auditors for review and as such, we are confused by the assertion that
“...there was no evidence to support the training status of all supervisors (who either received or
did not receive training).” Prior to the LMS, DHS developed its own internal training tracking
system using an Access Database. We are confident that these steps fully addressed the audit
finding.

--- Page 88 ---
Maryland Department of Transportation
Draft Audit Responses
State Employee Performance Evaluation Program
Performance Audit
Objective 3
Assess Selected Agencies’ Procedures for Monitoring the Proper Completion of
Performance Evaluations for Their Employees and Providing Related Training to
Supervisors
Finding 6
Certain agencies that were not using available personnel system records to monitor
completion of performance appraisals had many employees who were not evaluated. None
of the five agencies reviewed had established controls over the recording of evaluation data
in the personnel systems.
Recommendation 6
We recommend that
a. DPSCS, MDH, and MDOT establish procedures, such as routine monitoring of personnel
system data, to ensure employee performance evaluations are completed as required by
statute or regulation;
b. All five agencies establish processing controls to ensure all completed evaluations had been
accounted for and accurately recorded in the applicable personnel system; and
c. MDOT maintain documentation to support evaluation data reported annually to OPSB.
Response – MDOT concurs with auditors’ recommendations, specifically-
a. The MDOT TSO Office of Human Resources (OHR) will reissue TSHRS Policy 7A and
other pertinent documents to Transportation Business Unit (TBU) Administrators and TBU
Human Resource (HR) Managers. OHR will generate TBU quarterly reports of employee
performance appraisal ratings entered into HRIS for previous calendar year appraisals. The
reports will be distributed to the MDOT Deputy Secretaries, TBU Administrators, and TBU
HR Managers. These reports will be used by the TBUs to verify reporting and essential
elements are completed as required. We anticipate beginning distribution of these reports in
July 2018.
b. Each June, MDOT TBUs will conduct an annual review of 5% of career service employees’
personnel records to ensure completed ratings and essential elements are entered and accurate
in HRIS . These reviews will be documented and retained for audit purposes. TSO OHR
will provide each TBU HR Manager with the selected 5% Employee’s Identification Number
(EIN) to conduct the review. These controls will be in place for the calendar year 2018
performance appraisals.
c. The OHR will provide guidance to the MDOT TBU HR Managers to reinforce maintaining
supporting documentation for data submitted to OPSB. The guidance will be issued in
conjunction with the actions detailed in the response for 6a.

--- Page 89 ---
Finding 7
None of the five agencies reviewed had effectively monitored the content of performance
evaluations given to employees for compliance with legal requirements or policy.
Recommendation 7
We recommend that
a. The five agencies develop procedures to monitor the content of end -of-cycle or annual
performance evaluations given to employees for compliance with legal requirements or
policy;
b. The four agencies in SPMS ensure that measurable and objective performance standards have
been established for each position description, and
c. MDOT ensure that development plans and criteria assessment sheets are prepared for each
appraisal and support the evaluation rating.
Response – MDOT concurs with auditors’ recommendations, specifically-
a. MDOT will conduct annual reviews, as required by legal and policy requirements, which will
be documented and retained for audit purposes. These controls will be in place for the
calendar year 2018 performance appraisals.
b. Recommendation not applicable to MDOT.
c. Each September, MDOT TSO OHR will conduct an annual review by systematically
selecting 5% of MDOT career service employees’ personnel records to ensure HRIS entries
and TBU personnel files match, include the essential elements of the performance evaluation
process, and support the appraisal ratings. These reviews will be documented and retained
for audit purposes. These controls will be in place for the calendar year 2018 performance
appraisals.
Finding 8
None of the five agencies reviewed had established a documented process to sufficiently
track and monitor each of their supervisors to ensure had received performance appraisal
training.
Recommendation 8
We recommend that
a. The agencies cited above establish a documented process to track and monitor whether each
of their supervisors has received performance appraisal training and to ensure training
requirements are met; and
b. MDOT formalize its training expectations and, in doing so, consider mandating such training
for each supervisor.
Response – MDOT concurs with auditors’ recommendations, specifically-
a. MDOT is currently developing a uniform learning management system (LMS) platform for
all TBUs that will allow for centralized monitoring, distribution, and tracking of training to
all MDOT employees and supervisors. It is anticipated that the MDOT LMS will be
implemented by the end of calendar year 2018.
b. MDOT will establish a formal training module for supervisors that reinforces the
requirements, as stated in TSHRS Policy 7A and other pertinent documents, and stresses the
importance of the performance appraisal process. It is anticipated that pilot training modules
will be completed by the end of calendar year 2018.

--- Page 90 ---
A T
UDIT EAM
Raymond G. Burton, Jr., CPA, CFE
Audit Manager
Abdullah I. Adam, CFE
Senior Auditor
Matusala Y. Abishe
Monica G. Pressley
Matthew P. Henry
Staff Auditors